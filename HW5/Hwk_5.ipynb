{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "In this exercise, we will practice how to use deep neural networks on image data. We will be using the popular [Fashion mnist](https://www.tensorflow.org/datasets/catalog/fashion_mnist), which consists of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image associated with a label from 10 classes. Our goal is to build a neural network model to predict the label of a given image. We will achieve this in the following exercises.\n",
    "\n",
    "### Exercise 1(a) (2 points)\n",
    "\n",
    "Load the below libraries.\n",
    "\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(b) (2 points)\n",
    "\n",
    "Load the `fashion_mnist` data as follows:\n",
    "\n",
    "```\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(c) (2 points)\n",
    "\n",
    "Report the shape of the `train` and `test` data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (60000, 28, 28)\n",
      "Test data shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print('Train data shape:', x_train.shape)\n",
    "print('Test data shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execise 1(d) (12 points)\n",
    "\n",
    "Build a CNN model as follows:\n",
    "\n",
    "- Change the digit labels to 0-1 encoding.\n",
    "- The CNN model should have the following layers in the given order:\n",
    "    - `Conv2D` with 32 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Conv2D` with 32 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Flatten`\n",
    "    - `Dense` with 128 neurons and `activation=relu`\n",
    "    - `Dense` with 10 neurons and `activation=softmax`\n",
    "- Compile the network with the following:\n",
    "    - `optimizer='adam'`\n",
    "    - `loss='categorical_crossentropy'`\n",
    "    - `metrics=['accuracy']`\n",
    "- Train the deep neural network with `epochs=50`, `batch_size=128`, and `validation_split=0.1`.\n",
    "- Evaluate the model on the `test` data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmgma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - accuracy: 0.6629 - loss: 4.3648 - val_accuracy: 0.8425 - val_loss: 0.4489\n",
      "Epoch 2/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.8510 - loss: 0.4169 - val_accuracy: 0.8630 - val_loss: 0.3766\n",
      "Epoch 3/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.8757 - loss: 0.3491 - val_accuracy: 0.8703 - val_loss: 0.3571\n",
      "Epoch 4/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.8876 - loss: 0.3064 - val_accuracy: 0.8760 - val_loss: 0.3361\n",
      "Epoch 5/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.8952 - loss: 0.2809 - val_accuracy: 0.8757 - val_loss: 0.3476\n",
      "Epoch 6/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9007 - loss: 0.2624 - val_accuracy: 0.8810 - val_loss: 0.3438\n",
      "Epoch 7/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9032 - loss: 0.2491 - val_accuracy: 0.8825 - val_loss: 0.3258\n",
      "Epoch 8/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9122 - loss: 0.2322 - val_accuracy: 0.8850 - val_loss: 0.3320\n",
      "Epoch 9/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9136 - loss: 0.2180 - val_accuracy: 0.8860 - val_loss: 0.3274\n",
      "Epoch 10/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.9202 - loss: 0.2101 - val_accuracy: 0.8805 - val_loss: 0.3534\n",
      "Epoch 11/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9243 - loss: 0.1998 - val_accuracy: 0.8892 - val_loss: 0.3484\n",
      "Epoch 12/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9326 - loss: 0.1803 - val_accuracy: 0.8942 - val_loss: 0.3178\n",
      "Epoch 13/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9336 - loss: 0.1707 - val_accuracy: 0.8908 - val_loss: 0.3424\n",
      "Epoch 14/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9364 - loss: 0.1663 - val_accuracy: 0.8880 - val_loss: 0.3758\n",
      "Epoch 15/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9388 - loss: 0.1561 - val_accuracy: 0.8912 - val_loss: 0.3487\n",
      "Epoch 16/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9457 - loss: 0.1411 - val_accuracy: 0.8857 - val_loss: 0.3850\n",
      "Epoch 17/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9459 - loss: 0.1446 - val_accuracy: 0.8913 - val_loss: 0.3597\n",
      "Epoch 18/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9506 - loss: 0.1318 - val_accuracy: 0.8873 - val_loss: 0.3815\n",
      "Epoch 19/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9552 - loss: 0.1204 - val_accuracy: 0.8812 - val_loss: 0.4254\n",
      "Epoch 20/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9541 - loss: 0.1244 - val_accuracy: 0.8867 - val_loss: 0.4161\n",
      "Epoch 21/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9588 - loss: 0.1132 - val_accuracy: 0.8908 - val_loss: 0.4141\n",
      "Epoch 22/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9585 - loss: 0.1080 - val_accuracy: 0.8908 - val_loss: 0.4162\n",
      "Epoch 23/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9618 - loss: 0.1000 - val_accuracy: 0.8897 - val_loss: 0.4376\n",
      "Epoch 24/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9621 - loss: 0.1021 - val_accuracy: 0.8815 - val_loss: 0.4900\n",
      "Epoch 25/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.9656 - loss: 0.0895 - val_accuracy: 0.8892 - val_loss: 0.4834\n",
      "Epoch 26/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9681 - loss: 0.0843 - val_accuracy: 0.8895 - val_loss: 0.4679\n",
      "Epoch 27/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9671 - loss: 0.0879 - val_accuracy: 0.8867 - val_loss: 0.4744\n",
      "Epoch 28/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9671 - loss: 0.0867 - val_accuracy: 0.8880 - val_loss: 0.5182\n",
      "Epoch 29/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9696 - loss: 0.0809 - val_accuracy: 0.8853 - val_loss: 0.5355\n",
      "Epoch 30/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9753 - loss: 0.0655 - val_accuracy: 0.8890 - val_loss: 0.5278\n",
      "Epoch 31/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9754 - loss: 0.0661 - val_accuracy: 0.8867 - val_loss: 0.5753\n",
      "Epoch 32/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9740 - loss: 0.0708 - val_accuracy: 0.8898 - val_loss: 0.6111\n",
      "Epoch 33/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9790 - loss: 0.0562 - val_accuracy: 0.8908 - val_loss: 0.6330\n",
      "Epoch 34/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9770 - loss: 0.0626 - val_accuracy: 0.8875 - val_loss: 0.6733\n",
      "Epoch 35/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9768 - loss: 0.0621 - val_accuracy: 0.8888 - val_loss: 0.6571\n",
      "Epoch 36/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9801 - loss: 0.0537 - val_accuracy: 0.8825 - val_loss: 0.6835\n",
      "Epoch 37/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9796 - loss: 0.0573 - val_accuracy: 0.8852 - val_loss: 0.7079\n",
      "Epoch 38/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9801 - loss: 0.0556 - val_accuracy: 0.8877 - val_loss: 0.7235\n",
      "Epoch 39/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9825 - loss: 0.0501 - val_accuracy: 0.8868 - val_loss: 0.7815\n",
      "Epoch 40/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9813 - loss: 0.0547 - val_accuracy: 0.8817 - val_loss: 0.7465\n",
      "Epoch 41/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9831 - loss: 0.0476 - val_accuracy: 0.8888 - val_loss: 0.7215\n",
      "Epoch 42/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.9822 - loss: 0.0489 - val_accuracy: 0.8845 - val_loss: 0.8187\n",
      "Epoch 43/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9845 - loss: 0.0463 - val_accuracy: 0.8843 - val_loss: 0.7391\n",
      "Epoch 44/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9820 - loss: 0.0506 - val_accuracy: 0.8910 - val_loss: 0.7757\n",
      "Epoch 45/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9848 - loss: 0.0431 - val_accuracy: 0.8892 - val_loss: 0.8136\n",
      "Epoch 46/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9835 - loss: 0.0473 - val_accuracy: 0.8872 - val_loss: 0.8558\n",
      "Epoch 47/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9879 - loss: 0.0334 - val_accuracy: 0.8885 - val_loss: 0.8342\n",
      "Epoch 48/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9876 - loss: 0.0368 - val_accuracy: 0.8875 - val_loss: 0.9011\n",
      "Epoch 49/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9850 - loss: 0.0434 - val_accuracy: 0.8857 - val_loss: 0.8586\n",
      "Epoch 50/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9845 - loss: 0.0438 - val_accuracy: 0.8865 - val_loss: 0.8895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x276ffd9e290>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "md1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "md1.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "md1.fit(x_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execise 1(e) (12 points)\n",
    "\n",
    "Build a CNN model as follows:\n",
    "\n",
    "- The CNN model should have the following layers in the given order:\n",
    "    - `Conv2D` with 64 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Conv2D` with 64 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Conv2D` with 64 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Flatten`\n",
    "    - `Dense` with 128 neurons and `activation=relu`\n",
    "    - `Dense` with 10 neurons and `activation=softmax`\n",
    "- Compile the network with the following:\n",
    "    - `optimizer='adam'`\n",
    "    - `loss='categorical_crossentropy'`\n",
    "    - `metrics=['accuracy']`\n",
    "- Train the deep neural network with `epochs=50`, `batch_size=128`, and `validation_split=0.1`.\n",
    "- Evaluate the model on the `test` data set.\n",
    "\n",
    "Notice that there is no need to 0-1 encode the target labels; you can go ahead and train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmgma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - accuracy: 0.6481 - loss: 1.9074 - val_accuracy: 0.8088 - val_loss: 0.5169\n",
      "Epoch 2/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.8291 - loss: 0.4682 - val_accuracy: 0.8208 - val_loss: 0.4794\n",
      "Epoch 3/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.8463 - loss: 0.4138 - val_accuracy: 0.8597 - val_loss: 0.3868\n",
      "Epoch 4/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.8676 - loss: 0.3570 - val_accuracy: 0.8640 - val_loss: 0.3724\n",
      "Epoch 5/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.8790 - loss: 0.3326 - val_accuracy: 0.8637 - val_loss: 0.3684\n",
      "Epoch 6/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 44ms/step - accuracy: 0.8867 - loss: 0.3047 - val_accuracy: 0.8743 - val_loss: 0.3456\n",
      "Epoch 7/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.8951 - loss: 0.2853 - val_accuracy: 0.8698 - val_loss: 0.3576\n",
      "Epoch 8/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.8994 - loss: 0.2711 - val_accuracy: 0.8810 - val_loss: 0.3377\n",
      "Epoch 9/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - accuracy: 0.9032 - loss: 0.2610 - val_accuracy: 0.8788 - val_loss: 0.3415\n",
      "Epoch 10/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 41ms/step - accuracy: 0.9088 - loss: 0.2461 - val_accuracy: 0.8767 - val_loss: 0.3442\n",
      "Epoch 11/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 42ms/step - accuracy: 0.9120 - loss: 0.2341 - val_accuracy: 0.8762 - val_loss: 0.3673\n",
      "Epoch 12/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9159 - loss: 0.2252 - val_accuracy: 0.8752 - val_loss: 0.3512\n",
      "Epoch 13/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 42ms/step - accuracy: 0.9203 - loss: 0.2141 - val_accuracy: 0.8833 - val_loss: 0.3387\n",
      "Epoch 14/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9221 - loss: 0.2054 - val_accuracy: 0.8862 - val_loss: 0.3382\n",
      "Epoch 15/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.9267 - loss: 0.1986 - val_accuracy: 0.8822 - val_loss: 0.3690\n",
      "Epoch 16/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.9285 - loss: 0.1892 - val_accuracy: 0.8735 - val_loss: 0.3917\n",
      "Epoch 17/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.9301 - loss: 0.1892 - val_accuracy: 0.8800 - val_loss: 0.3765\n",
      "Epoch 18/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.9340 - loss: 0.1770 - val_accuracy: 0.8872 - val_loss: 0.3693\n",
      "Epoch 19/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9396 - loss: 0.1633 - val_accuracy: 0.8700 - val_loss: 0.4018\n",
      "Epoch 20/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9370 - loss: 0.1679 - val_accuracy: 0.8818 - val_loss: 0.3857\n",
      "Epoch 21/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.9411 - loss: 0.1574 - val_accuracy: 0.8792 - val_loss: 0.4056\n",
      "Epoch 22/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9438 - loss: 0.1486 - val_accuracy: 0.8838 - val_loss: 0.4155\n",
      "Epoch 23/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 41ms/step - accuracy: 0.9459 - loss: 0.1398 - val_accuracy: 0.8800 - val_loss: 0.4336\n",
      "Epoch 24/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.9485 - loss: 0.1400 - val_accuracy: 0.8787 - val_loss: 0.4289\n",
      "Epoch 25/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.9499 - loss: 0.1327 - val_accuracy: 0.8815 - val_loss: 0.4474\n",
      "Epoch 26/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9554 - loss: 0.1181 - val_accuracy: 0.8785 - val_loss: 0.4655\n",
      "Epoch 27/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.9515 - loss: 0.1290 - val_accuracy: 0.8745 - val_loss: 0.4801\n",
      "Epoch 28/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - accuracy: 0.9526 - loss: 0.1241 - val_accuracy: 0.8780 - val_loss: 0.4674\n",
      "Epoch 29/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 41ms/step - accuracy: 0.9571 - loss: 0.1178 - val_accuracy: 0.8793 - val_loss: 0.4714\n",
      "Epoch 30/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 41ms/step - accuracy: 0.9567 - loss: 0.1128 - val_accuracy: 0.8797 - val_loss: 0.5074\n",
      "Epoch 31/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9582 - loss: 0.1087 - val_accuracy: 0.8803 - val_loss: 0.5010\n",
      "Epoch 32/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.9613 - loss: 0.1039 - val_accuracy: 0.8800 - val_loss: 0.5072\n",
      "Epoch 33/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9590 - loss: 0.1061 - val_accuracy: 0.8797 - val_loss: 0.5233\n",
      "Epoch 34/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9624 - loss: 0.0984 - val_accuracy: 0.8852 - val_loss: 0.4950\n",
      "Epoch 35/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.9667 - loss: 0.0912 - val_accuracy: 0.8775 - val_loss: 0.5758\n",
      "Epoch 36/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.9623 - loss: 0.0999 - val_accuracy: 0.8817 - val_loss: 0.5533\n",
      "Epoch 37/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9679 - loss: 0.0889 - val_accuracy: 0.8767 - val_loss: 0.5663\n",
      "Epoch 38/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.9648 - loss: 0.0951 - val_accuracy: 0.8790 - val_loss: 0.5871\n",
      "Epoch 39/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - accuracy: 0.9681 - loss: 0.0860 - val_accuracy: 0.8777 - val_loss: 0.6051\n",
      "Epoch 40/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 41ms/step - accuracy: 0.9708 - loss: 0.0789 - val_accuracy: 0.8698 - val_loss: 0.6241\n",
      "Epoch 41/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.9714 - loss: 0.0762 - val_accuracy: 0.8763 - val_loss: 0.6012\n",
      "Epoch 42/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9714 - loss: 0.0774 - val_accuracy: 0.8810 - val_loss: 0.6487\n",
      "Epoch 43/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9703 - loss: 0.0781 - val_accuracy: 0.8745 - val_loss: 0.6459\n",
      "Epoch 44/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9665 - loss: 0.0898 - val_accuracy: 0.8778 - val_loss: 0.6349\n",
      "Epoch 45/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9741 - loss: 0.0719 - val_accuracy: 0.8745 - val_loss: 0.6264\n",
      "Epoch 46/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 41ms/step - accuracy: 0.9719 - loss: 0.0769 - val_accuracy: 0.8775 - val_loss: 0.6645\n",
      "Epoch 47/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9736 - loss: 0.0717 - val_accuracy: 0.8758 - val_loss: 0.7256\n",
      "Epoch 48/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9716 - loss: 0.0783 - val_accuracy: 0.8743 - val_loss: 0.7200\n",
      "Epoch 49/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.9773 - loss: 0.0629 - val_accuracy: 0.8750 - val_loss: 0.7130\n",
      "Epoch 50/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - accuracy: 0.9766 - loss: 0.0646 - val_accuracy: 0.8770 - val_loss: 0.7593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27680c530d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "md2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "md2.fit(x_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execise 1(f) (12 points)\n",
    "\n",
    "Build a CNN model as follows:\n",
    "\n",
    "- The CNN model should have the following layers in the given order:\n",
    "    - `Conv2D` with 32 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Conv2D` with 64 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Conv2D` with 128 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Flatten`\n",
    "    - `Dense` with 128 neurons and `activation=relu`\n",
    "    - `Dense` with 10 neurons and `activation=softmax`\n",
    "- Compile the network with the following:\n",
    "    - `optimizer='adam'`\n",
    "    - `loss='categorical_crossentropy'`\n",
    "    - `metrics=['accuracy']`\n",
    "- Train the deep neural network with `epochs=50`, `batch_size=128`, and `validation_split=0.1`.\n",
    "- Evaluate the model on the `test` data set.\n",
    "\n",
    "Notice that there is no need to 0-1 encode the target labels; you can go ahead and train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - accuracy: 0.6636 - loss: 2.0795 - val_accuracy: 0.8302 - val_loss: 0.4619\n",
      "Epoch 2/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.8436 - loss: 0.4266 - val_accuracy: 0.8507 - val_loss: 0.4057\n",
      "Epoch 3/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.8644 - loss: 0.3630 - val_accuracy: 0.8690 - val_loss: 0.3632\n",
      "Epoch 4/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.8800 - loss: 0.3236 - val_accuracy: 0.8690 - val_loss: 0.3611\n",
      "Epoch 5/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.8906 - loss: 0.2937 - val_accuracy: 0.8690 - val_loss: 0.3555\n",
      "Epoch 6/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.8973 - loss: 0.2789 - val_accuracy: 0.8817 - val_loss: 0.3446\n",
      "Epoch 7/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9078 - loss: 0.2508 - val_accuracy: 0.8787 - val_loss: 0.3488\n",
      "Epoch 8/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9091 - loss: 0.2429 - val_accuracy: 0.8893 - val_loss: 0.3175\n",
      "Epoch 9/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9134 - loss: 0.2308 - val_accuracy: 0.8735 - val_loss: 0.3569\n",
      "Epoch 10/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9200 - loss: 0.2147 - val_accuracy: 0.8837 - val_loss: 0.3535\n",
      "Epoch 11/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9247 - loss: 0.2007 - val_accuracy: 0.8753 - val_loss: 0.3639\n",
      "Epoch 12/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9285 - loss: 0.1910 - val_accuracy: 0.8887 - val_loss: 0.3469\n",
      "Epoch 13/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9348 - loss: 0.1740 - val_accuracy: 0.8870 - val_loss: 0.3527\n",
      "Epoch 14/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9383 - loss: 0.1663 - val_accuracy: 0.8848 - val_loss: 0.3805\n",
      "Epoch 15/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9393 - loss: 0.1629 - val_accuracy: 0.8795 - val_loss: 0.4067\n",
      "Epoch 16/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9402 - loss: 0.1555 - val_accuracy: 0.8905 - val_loss: 0.3960\n",
      "Epoch 17/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9460 - loss: 0.1415 - val_accuracy: 0.8830 - val_loss: 0.4185\n",
      "Epoch 18/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9478 - loss: 0.1398 - val_accuracy: 0.8865 - val_loss: 0.4056\n",
      "Epoch 19/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9492 - loss: 0.1343 - val_accuracy: 0.8918 - val_loss: 0.4305\n",
      "Epoch 20/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9549 - loss: 0.1202 - val_accuracy: 0.8790 - val_loss: 0.4802\n",
      "Epoch 21/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9509 - loss: 0.1310 - val_accuracy: 0.8828 - val_loss: 0.4426\n",
      "Epoch 22/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9574 - loss: 0.1126 - val_accuracy: 0.8702 - val_loss: 0.5033\n",
      "Epoch 23/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9572 - loss: 0.1131 - val_accuracy: 0.8835 - val_loss: 0.4939\n",
      "Epoch 24/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9603 - loss: 0.1040 - val_accuracy: 0.8785 - val_loss: 0.5011\n",
      "Epoch 25/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9624 - loss: 0.0991 - val_accuracy: 0.8828 - val_loss: 0.5014\n",
      "Epoch 26/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9646 - loss: 0.0940 - val_accuracy: 0.8845 - val_loss: 0.4983\n",
      "Epoch 27/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9660 - loss: 0.0906 - val_accuracy: 0.8840 - val_loss: 0.5101\n",
      "Epoch 28/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9674 - loss: 0.0878 - val_accuracy: 0.8847 - val_loss: 0.5529\n",
      "Epoch 29/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9700 - loss: 0.0824 - val_accuracy: 0.8808 - val_loss: 0.5708\n",
      "Epoch 30/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9682 - loss: 0.0856 - val_accuracy: 0.8825 - val_loss: 0.5735\n",
      "Epoch 31/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9717 - loss: 0.0759 - val_accuracy: 0.8822 - val_loss: 0.5768\n",
      "Epoch 32/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.9717 - loss: 0.0793 - val_accuracy: 0.8877 - val_loss: 0.6086\n",
      "Epoch 33/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9782 - loss: 0.0602 - val_accuracy: 0.8828 - val_loss: 0.5796\n",
      "Epoch 34/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.9727 - loss: 0.0755 - val_accuracy: 0.8737 - val_loss: 0.6072\n",
      "Epoch 35/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9753 - loss: 0.0653 - val_accuracy: 0.8845 - val_loss: 0.6741\n",
      "Epoch 36/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9782 - loss: 0.0629 - val_accuracy: 0.8795 - val_loss: 0.6903\n",
      "Epoch 37/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9738 - loss: 0.0722 - val_accuracy: 0.8885 - val_loss: 0.6230\n",
      "Epoch 38/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9814 - loss: 0.0496 - val_accuracy: 0.8817 - val_loss: 0.6818\n",
      "Epoch 39/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9793 - loss: 0.0567 - val_accuracy: 0.8808 - val_loss: 0.7311\n",
      "Epoch 40/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9751 - loss: 0.0690 - val_accuracy: 0.8825 - val_loss: 0.7733\n",
      "Epoch 41/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9779 - loss: 0.0617 - val_accuracy: 0.8800 - val_loss: 0.7120\n",
      "Epoch 42/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9806 - loss: 0.0529 - val_accuracy: 0.8830 - val_loss: 0.7970\n",
      "Epoch 43/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9801 - loss: 0.0561 - val_accuracy: 0.8832 - val_loss: 0.6967\n",
      "Epoch 44/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.9790 - loss: 0.0591 - val_accuracy: 0.8812 - val_loss: 0.7266\n",
      "Epoch 45/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9800 - loss: 0.0548 - val_accuracy: 0.8813 - val_loss: 0.7648\n",
      "Epoch 46/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9841 - loss: 0.0463 - val_accuracy: 0.8797 - val_loss: 0.8169\n",
      "Epoch 47/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9853 - loss: 0.0434 - val_accuracy: 0.8832 - val_loss: 0.7893\n",
      "Epoch 48/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9813 - loss: 0.0543 - val_accuracy: 0.8807 - val_loss: 0.7772\n",
      "Epoch 49/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9834 - loss: 0.0471 - val_accuracy: 0.8882 - val_loss: 0.7573\n",
      "Epoch 50/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9856 - loss: 0.0415 - val_accuracy: 0.8737 - val_loss: 0.7836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2768d28c9d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(128, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "md3.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "md3.fit(x_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(g) (3 points)\n",
    "\n",
    "Based on the results from parts 1(d)-1(f), which model would you use to predict the label of the `fashion_mnist` data set? Please be specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888000249862671\n",
      "0.8773000240325928\n",
      "0.8759999871253967\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = md1.evaluate(x_test, y_test, verbose = 0)\n",
    "print(test_acc)\n",
    "test_loss, test_acc = md2.evaluate(x_test, y_test, verbose = 0)\n",
    "print(test_acc)\n",
    "test_loss, test_acc = md3.evaluate(x_test, y_test, verbose = 0)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on my results I would use the 1st model because it has the highest accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(h) (15 points)\n",
    "\n",
    "Improve the performance of the best model architecture. You may consider adding more layers, change the activation function, add `Dropout` layers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmgma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - accuracy: 0.5912 - loss: 4.6075 - val_accuracy: 0.8000 - val_loss: 0.5453\n",
      "Epoch 2/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.7842 - loss: 0.5802 - val_accuracy: 0.8412 - val_loss: 0.4282\n",
      "Epoch 3/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.8203 - loss: 0.4814 - val_accuracy: 0.8615 - val_loss: 0.3897\n",
      "Epoch 4/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.8411 - loss: 0.4224 - val_accuracy: 0.8682 - val_loss: 0.3604\n",
      "Epoch 5/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.8608 - loss: 0.3788 - val_accuracy: 0.8738 - val_loss: 0.3389\n",
      "Epoch 6/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.8640 - loss: 0.3581 - val_accuracy: 0.8822 - val_loss: 0.3191\n",
      "Epoch 7/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.8693 - loss: 0.3467 - val_accuracy: 0.8787 - val_loss: 0.3176\n",
      "Epoch 8/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.8777 - loss: 0.3240 - val_accuracy: 0.8873 - val_loss: 0.2990\n",
      "Epoch 9/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.8810 - loss: 0.3142 - val_accuracy: 0.8920 - val_loss: 0.2884\n",
      "Epoch 10/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.8919 - loss: 0.2901 - val_accuracy: 0.8928 - val_loss: 0.2929\n",
      "Epoch 11/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.8920 - loss: 0.2851 - val_accuracy: 0.8945 - val_loss: 0.2820\n",
      "Epoch 12/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.8921 - loss: 0.2841 - val_accuracy: 0.8973 - val_loss: 0.2836\n",
      "Epoch 13/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.8958 - loss: 0.2712 - val_accuracy: 0.8877 - val_loss: 0.2828\n",
      "Epoch 14/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9019 - loss: 0.2623 - val_accuracy: 0.9002 - val_loss: 0.2800\n",
      "Epoch 15/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9022 - loss: 0.2607 - val_accuracy: 0.9008 - val_loss: 0.2659\n",
      "Epoch 16/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9011 - loss: 0.2544 - val_accuracy: 0.8970 - val_loss: 0.2798\n",
      "Epoch 17/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9071 - loss: 0.2415 - val_accuracy: 0.8983 - val_loss: 0.2691\n",
      "Epoch 18/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9111 - loss: 0.2357 - val_accuracy: 0.9040 - val_loss: 0.2612\n",
      "Epoch 19/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9107 - loss: 0.2322 - val_accuracy: 0.9003 - val_loss: 0.2718\n",
      "Epoch 20/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9148 - loss: 0.2254 - val_accuracy: 0.9080 - val_loss: 0.2540\n",
      "Epoch 21/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9127 - loss: 0.2269 - val_accuracy: 0.9008 - val_loss: 0.2696\n",
      "Epoch 22/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9173 - loss: 0.2183 - val_accuracy: 0.9030 - val_loss: 0.2639\n",
      "Epoch 23/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9189 - loss: 0.2104 - val_accuracy: 0.9075 - val_loss: 0.2549\n",
      "Epoch 24/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9209 - loss: 0.2053 - val_accuracy: 0.9058 - val_loss: 0.2556\n",
      "Epoch 25/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9231 - loss: 0.2042 - val_accuracy: 0.9053 - val_loss: 0.2669\n",
      "Epoch 26/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9243 - loss: 0.1981 - val_accuracy: 0.9062 - val_loss: 0.2538\n",
      "Epoch 27/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9247 - loss: 0.1993 - val_accuracy: 0.9062 - val_loss: 0.2701\n",
      "Epoch 28/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9252 - loss: 0.1965 - val_accuracy: 0.9032 - val_loss: 0.2633\n",
      "Epoch 29/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9279 - loss: 0.1877 - val_accuracy: 0.9065 - val_loss: 0.2711\n",
      "Epoch 30/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9315 - loss: 0.1800 - val_accuracy: 0.9033 - val_loss: 0.2689\n",
      "Epoch 31/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9300 - loss: 0.1814 - val_accuracy: 0.9127 - val_loss: 0.2510\n",
      "Epoch 32/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9315 - loss: 0.1777 - val_accuracy: 0.9088 - val_loss: 0.2568\n",
      "Epoch 33/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9318 - loss: 0.1797 - val_accuracy: 0.9095 - val_loss: 0.2679\n",
      "Epoch 34/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9367 - loss: 0.1700 - val_accuracy: 0.9077 - val_loss: 0.2774\n",
      "Epoch 35/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9353 - loss: 0.1707 - val_accuracy: 0.8988 - val_loss: 0.2894\n",
      "Epoch 36/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9370 - loss: 0.1646 - val_accuracy: 0.9060 - val_loss: 0.2795\n",
      "Epoch 37/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9365 - loss: 0.1682 - val_accuracy: 0.9105 - val_loss: 0.2500\n",
      "Epoch 38/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9354 - loss: 0.1692 - val_accuracy: 0.9110 - val_loss: 0.2753\n",
      "Epoch 39/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9368 - loss: 0.1657 - val_accuracy: 0.9095 - val_loss: 0.2714\n",
      "Epoch 40/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9388 - loss: 0.1608 - val_accuracy: 0.9110 - val_loss: 0.2745\n",
      "Epoch 41/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9394 - loss: 0.1618 - val_accuracy: 0.9118 - val_loss: 0.2639\n",
      "Epoch 42/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9388 - loss: 0.1592 - val_accuracy: 0.9055 - val_loss: 0.2898\n",
      "Epoch 43/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9389 - loss: 0.1596 - val_accuracy: 0.9095 - val_loss: 0.2790\n",
      "Epoch 44/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9419 - loss: 0.1501 - val_accuracy: 0.9072 - val_loss: 0.2817\n",
      "Epoch 45/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9413 - loss: 0.1558 - val_accuracy: 0.9110 - val_loss: 0.2740\n",
      "Epoch 46/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9443 - loss: 0.1483 - val_accuracy: 0.9105 - val_loss: 0.2913\n",
      "Epoch 47/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9391 - loss: 0.1593 - val_accuracy: 0.9023 - val_loss: 0.3022\n",
      "Epoch 48/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9440 - loss: 0.1516 - val_accuracy: 0.9140 - val_loss: 0.2666\n",
      "Epoch 49/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9436 - loss: 0.1466 - val_accuracy: 0.9075 - val_loss: 0.2950\n",
      "Epoch 50/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9415 - loss: 0.1512 - val_accuracy: 0.9115 - val_loss: 0.2825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27699fee290>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "md4.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "md4.fit(x_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9036999940872192\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = md4.evaluate(x_test, y_test, verbose = 0)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding dropout of .2 improved my best models score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
