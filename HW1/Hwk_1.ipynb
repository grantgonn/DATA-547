{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 \n",
    "\n",
    "In this exercise, we continue practicing `TensorFlow` basiscs. \n",
    "\n",
    "### Exercise 1(a) (2 points) \n",
    "\n",
    "Import `TensorFlow` and `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(b) (2 points)\n",
    "\n",
    "Create a constant `TensorFlow` tensor with a specific data type (e.g., `float32`) and print its data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_c = tf.constant(5, dtype='float32')\n",
    "t_c.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(c) (3 points)\n",
    "\n",
    "Creates a constant `TensorFlow` tensor and then change from one data type to another (e.g., frim `int32` to `float64`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting dtype: <dtype: 'int32'>\n",
      "ending dtype: <dtype: 'float64'>\n"
     ]
    }
   ],
   "source": [
    "t_c = tf.constant(5, dtype='int32')\n",
    "print('starting dtype:', t_c.dtype)\n",
    "\n",
    "t_c = tf.cast(t_c, dtype='float64')\n",
    "print('ending dtype:', t_c.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(d) (2 points)\n",
    "\n",
    "Creates a constant `TensorFlow` tensor with a string data type and print its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Grant'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_c = tf.constant('Grant', dtype='string')\n",
    "t_c.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "In this exercise, we will practice building a simple `Perceptron` model with `TensorFlow`. \n",
    "\n",
    "### Exercise 2(a) (3 points)\n",
    "\n",
    "If you don't have `sklearn` install, please install it as follows:\n",
    "\n",
    "```\n",
    "pip install -U scikit-learn\n",
    "```\n",
    "Then, load create a binary dataset as follows:\n",
    "\n",
    "```\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=10, n_redundant=0, random_state=1)\n",
    "y = y.reshape(-1, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X,y = make_classification(n_samples = 1000, n_features = 10, n_informative = 10, n_redundant = 0, random_state = 1)\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2(b) (2 points)\n",
    "\n",
    "Report the shape of `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2(c) (2 points)\n",
    "\n",
    "Report the number of `0`s and `1`s in `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of 0s: 500\n",
      "count of 1s 500\n"
     ]
    }
   ],
   "source": [
    "print('count of 0s:', np.sum(y==0))\n",
    "print('count of 1s', np.sum(y==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2(d) (3 points)\n",
    "\n",
    "Define the `perceptron` model. Make sure to use `sigmoid` as the activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmgma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape = (10,), activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2(e) (3 points)\n",
    "\n",
    "Compile the model from part 2(b). Use `optimizer='sgd'`, `loss='binary_crossentropy'`, and `metrics=['accuracy']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2(f) (3 points)\n",
    "\n",
    "Train the model with `epochs=10`, and `validation_split=0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3832 - loss: 1.2979 - val_accuracy: 0.4500 - val_loss: 0.9491\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4787 - loss: 0.9126 - val_accuracy: 0.6100 - val_loss: 0.6716\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5884 - loss: 0.7015 - val_accuracy: 0.7300 - val_loss: 0.5286\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7190 - loss: 0.5602 - val_accuracy: 0.8300 - val_loss: 0.4461\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7783 - loss: 0.5116 - val_accuracy: 0.8800 - val_loss: 0.3999\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8323 - loss: 0.4548 - val_accuracy: 0.9000 - val_loss: 0.3682\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8644 - loss: 0.4142 - val_accuracy: 0.9100 - val_loss: 0.3452\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8650 - loss: 0.4078 - val_accuracy: 0.9200 - val_loss: 0.3304\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8842 - loss: 0.3648 - val_accuracy: 0.9200 - val_loss: 0.3176\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8815 - loss: 0.3674 - val_accuracy: 0.9200 - val_loss: 0.3076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22be1046230>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2(g) (3 points)\n",
    "\n",
    "Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8854 - loss: 0.3715 \n",
      "Accuracy:89.60%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X,y)\n",
    "\n",
    "print(f'Accuracy:{accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2(h) (3 points)\n",
    "\n",
    "Use the model to make a prediction on the below data point.\n",
    "\n",
    "```\n",
    "[0.12777556,-3.64400522,-2.23268854,-1.82114386,1.75466361,0.1243966,1.03397657,2.35822076,1.01001752,0.56768485]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "prediction:\n",
      "[[0.76600856]]\n"
     ]
    }
   ],
   "source": [
    "dat = np.array([[0.12777556,-3.64400522,-2.23268854,-1.82114386,1.75466361,0.1243966,1.03397657,2.35822076,1.01001752,0.56768485]])\n",
    "\n",
    "predictions = model.predict(dat)\n",
    "print('prediction:')\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
