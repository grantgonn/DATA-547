{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 \n",
    "\n",
    "In this homework assignment, we will practice building regression models with `TensorFlow`.\n",
    "\n",
    "### Exercise 1(a) (2 points)\n",
    "\n",
    "Load the `numpy` and `tensorflow` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(b) (3 points)\n",
    "\n",
    "We will use the popular `California Housing` dataset from `sklearn`. For more info about the dataset can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#sklearn.datasets.fetch_california_housing). The `California Housing` dataset can load as follows:\n",
    "\n",
    "```\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "X,y = fetch_california_housing(return_X_y = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(c) (3 points)\n",
    "\n",
    "Using `train_test_split`, split the data into `train` (80%) and `test` (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(d) (2 points)\n",
    "\n",
    "Report the number of columns in `X_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(e) (6 points)\n",
    "\n",
    "Define the a neural network called `md_1` with one hidden layer with 8 neurons and `relu` as the activation function. Make sure to normalize the input features using `BatchNormalization()`. For more info about `BatchNormalization()`, see this [link](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmgma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "md_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(8, input_shape = (8,), activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(f) (3 points)\n",
    "\n",
    "Compile the `md_1` model. Use `optimizer='adam'`, `loss='mean_squared_error'`, and `metrics=['MeanSquaredError']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_1.compile(optimizer='adam', loss='mean_squared_error', metrics=['MeanSquaredError'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(g) (3 points)\n",
    "\n",
    "Train `md_1` using the `train` data with `epochs=20`, and `validation_split=0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - MeanSquaredError: 3.4575 - loss: 3.4575 - val_MeanSquaredError: 0.8139 - val_loss: 0.8139\n",
      "Epoch 2/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.7466 - loss: 0.7466 - val_MeanSquaredError: 0.6626 - val_loss: 0.6626\n",
      "Epoch 3/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.5879 - loss: 0.5879 - val_MeanSquaredError: 0.6100 - val_loss: 0.6100\n",
      "Epoch 4/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.5636 - loss: 0.5636 - val_MeanSquaredError: 0.5853 - val_loss: 0.5853\n",
      "Epoch 5/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.5274 - loss: 0.5274 - val_MeanSquaredError: 0.5729 - val_loss: 0.5729\n",
      "Epoch 6/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.5125 - loss: 0.5125 - val_MeanSquaredError: 0.5550 - val_loss: 0.5550\n",
      "Epoch 7/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4789 - loss: 0.4789 - val_MeanSquaredError: 0.5164 - val_loss: 0.5164\n",
      "Epoch 8/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4631 - loss: 0.4631 - val_MeanSquaredError: 0.5253 - val_loss: 0.5253\n",
      "Epoch 9/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4578 - loss: 0.4578 - val_MeanSquaredError: 0.5118 - val_loss: 0.5118\n",
      "Epoch 10/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4456 - loss: 0.4456 - val_MeanSquaredError: 0.5119 - val_loss: 0.5119\n",
      "Epoch 11/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4409 - loss: 0.4409 - val_MeanSquaredError: 0.5085 - val_loss: 0.5085\n",
      "Epoch 12/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4716 - loss: 0.4716 - val_MeanSquaredError: 0.4763 - val_loss: 0.4763\n",
      "Epoch 13/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4488 - loss: 0.4488 - val_MeanSquaredError: 0.4879 - val_loss: 0.4879\n",
      "Epoch 14/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4448 - loss: 0.4448 - val_MeanSquaredError: 0.5128 - val_loss: 0.5128\n",
      "Epoch 15/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4315 - loss: 0.4315 - val_MeanSquaredError: 0.4856 - val_loss: 0.4856\n",
      "Epoch 16/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4425 - loss: 0.4425 - val_MeanSquaredError: 0.4832 - val_loss: 0.4832\n",
      "Epoch 17/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4173 - loss: 0.4173 - val_MeanSquaredError: 0.4609 - val_loss: 0.4609\n",
      "Epoch 18/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4366 - loss: 0.4366 - val_MeanSquaredError: 0.4800 - val_loss: 0.4800\n",
      "Epoch 19/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4495 - loss: 0.4495 - val_MeanSquaredError: 0.4899 - val_loss: 0.4899\n",
      "Epoch 20/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4439 - loss: 0.4439 - val_MeanSquaredError: 0.4743 - val_loss: 0.4743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b21f52ba30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_1.fit(x_train, y_train, epochs=20, validation_split=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(h) (3 points)\n",
    "\n",
    "Evaluate `md_1` model on the `test` data. Report the `mean_squared_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - MeanSquaredError: 0.5382 - loss: 0.5382\n",
      "MSE:0.5170875787734985%\n"
     ]
    }
   ],
   "source": [
    "loss, MSE = md_1.evaluate(x_test, y_test)\n",
    "print(f'MSE:{MSE}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 (10 points)\n",
    "\n",
    "Define the a neural network called `md_2` as follows:\n",
    "\n",
    "- Normalize the input features using `BatchNormalization()`.\n",
    "- Two hidden layers with 8 neurons and `relu` as the activation function. \n",
    "- Compile the `md_2` model. Use `optimizer='adam'`, `loss='mean_squared_error'`, and `metrics=['MeanSquaredError']`. \n",
    "- Train `md_2` using the `train` data with `epochs=20`, and `validation_split=0.1`. \n",
    "- Finally, evaluate `md_2` model on the `test` data. Report the `mean_squared_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - MeanSquaredError: 2.5871 - loss: 2.5871 - val_MeanSquaredError: 0.5497 - val_loss: 0.5497\n",
      "Epoch 2/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4940 - loss: 0.4940 - val_MeanSquaredError: 0.5008 - val_loss: 0.5008\n",
      "Epoch 3/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4724 - loss: 0.4724 - val_MeanSquaredError: 0.5060 - val_loss: 0.5060\n",
      "Epoch 4/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4599 - loss: 0.4599 - val_MeanSquaredError: 0.4959 - val_loss: 0.4959\n",
      "Epoch 5/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4352 - loss: 0.4352 - val_MeanSquaredError: 0.4590 - val_loss: 0.4590\n",
      "Epoch 6/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4429 - loss: 0.4429 - val_MeanSquaredError: 0.4659 - val_loss: 0.4659\n",
      "Epoch 7/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4415 - loss: 0.4415 - val_MeanSquaredError: 0.4719 - val_loss: 0.4719\n",
      "Epoch 8/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4311 - loss: 0.4311 - val_MeanSquaredError: 0.4686 - val_loss: 0.4686\n",
      "Epoch 9/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4393 - loss: 0.4393 - val_MeanSquaredError: 0.4659 - val_loss: 0.4659\n",
      "Epoch 10/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4317 - loss: 0.4317 - val_MeanSquaredError: 0.4726 - val_loss: 0.4726\n",
      "Epoch 11/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4260 - loss: 0.4260 - val_MeanSquaredError: 0.5115 - val_loss: 0.5115\n",
      "Epoch 12/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4157 - loss: 0.4157 - val_MeanSquaredError: 0.5061 - val_loss: 0.5061\n",
      "Epoch 13/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4231 - loss: 0.4231 - val_MeanSquaredError: 0.4614 - val_loss: 0.4614\n",
      "Epoch 14/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4381 - loss: 0.4381 - val_MeanSquaredError: 0.4899 - val_loss: 0.4899\n",
      "Epoch 15/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4167 - loss: 0.4167 - val_MeanSquaredError: 0.4671 - val_loss: 0.4671\n",
      "Epoch 16/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4249 - loss: 0.4249 - val_MeanSquaredError: 0.4618 - val_loss: 0.4618\n",
      "Epoch 17/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4387 - loss: 0.4387 - val_MeanSquaredError: 0.4601 - val_loss: 0.4601\n",
      "Epoch 18/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4279 - loss: 0.4279 - val_MeanSquaredError: 0.4765 - val_loss: 0.4765\n",
      "Epoch 19/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4130 - loss: 0.4130 - val_MeanSquaredError: 0.4508 - val_loss: 0.4508\n",
      "Epoch 20/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4316 - loss: 0.4316 - val_MeanSquaredError: 0.4698 - val_loss: 0.4698\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - MeanSquaredError: 0.5324 - loss: 0.5324\n",
      "MSE:0.5142727494239807%\n"
     ]
    }
   ],
   "source": [
    "md_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(8, input_shape = (8,), activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "\n",
    "md_2.compile(optimizer='adam', loss='mean_squared_error', metrics=['MeanSquaredError'])\n",
    "\n",
    "md_2.fit(x_train, y_train, epochs=20, validation_split=.1)\n",
    "\n",
    "loss, MSE = md_2.evaluate(x_test, y_test)\n",
    "print(f'MSE:{MSE}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 (10 points)\n",
    "\n",
    "Define the a neural network called `md_3` as follows:\n",
    "\n",
    "- Normalize the input features using `BatchNormalization()`.\n",
    "- Two hidden layers with 8 neurons and `relu` as the activation function. \n",
    "- Add `Dropout(0.1)` after each layer.\n",
    "- Compile the `md_3` model using `optimizer='adam'`, `loss='mean_squared_error'`, and `metrics=['MeanSquaredError']`. \n",
    "- Train `md_3` using the `train` data with `epochs=20`, and `validation_split=0.1`. \n",
    "- Finally, evaluate `md_3` model on the `test` data. Report the `mean_squared_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - MeanSquaredError: 3.0739 - loss: 3.0739 - val_MeanSquaredError: 0.9740 - val_loss: 0.9740\n",
      "Epoch 2/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 1.0196 - loss: 1.0196 - val_MeanSquaredError: 0.6483 - val_loss: 0.6483\n",
      "Epoch 3/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.7865 - loss: 0.7865 - val_MeanSquaredError: 0.6250 - val_loss: 0.6250\n",
      "Epoch 4/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.6982 - loss: 0.6982 - val_MeanSquaredError: 0.5700 - val_loss: 0.5700\n",
      "Epoch 5/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.6392 - loss: 0.6392 - val_MeanSquaredError: 0.5333 - val_loss: 0.5333\n",
      "Epoch 6/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.6300 - loss: 0.6300 - val_MeanSquaredError: 0.5060 - val_loss: 0.5060\n",
      "Epoch 7/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.5829 - loss: 0.5829 - val_MeanSquaredError: 0.4903 - val_loss: 0.4903\n",
      "Epoch 8/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.5704 - loss: 0.5704 - val_MeanSquaredError: 0.4736 - val_loss: 0.4736\n",
      "Epoch 9/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.5489 - loss: 0.5489 - val_MeanSquaredError: 0.4946 - val_loss: 0.4946\n",
      "Epoch 10/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.5365 - loss: 0.5365 - val_MeanSquaredError: 0.4787 - val_loss: 0.4787\n",
      "Epoch 11/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.5115 - loss: 0.5115 - val_MeanSquaredError: 0.4936 - val_loss: 0.4936\n",
      "Epoch 12/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.5254 - loss: 0.5254 - val_MeanSquaredError: 0.4866 - val_loss: 0.4866\n",
      "Epoch 13/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.5128 - loss: 0.5128 - val_MeanSquaredError: 0.4758 - val_loss: 0.4758\n",
      "Epoch 14/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4817 - loss: 0.4817 - val_MeanSquaredError: 0.4670 - val_loss: 0.4670\n",
      "Epoch 15/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.5103 - loss: 0.5103 - val_MeanSquaredError: 0.4880 - val_loss: 0.4880\n",
      "Epoch 16/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.5117 - loss: 0.5117 - val_MeanSquaredError: 0.4809 - val_loss: 0.4809\n",
      "Epoch 17/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4856 - loss: 0.4856 - val_MeanSquaredError: 0.4829 - val_loss: 0.4829\n",
      "Epoch 18/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4864 - loss: 0.4864 - val_MeanSquaredError: 0.4646 - val_loss: 0.4646\n",
      "Epoch 19/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4963 - loss: 0.4963 - val_MeanSquaredError: 0.4669 - val_loss: 0.4669\n",
      "Epoch 20/20\n",
      "\u001b[1m465/465\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - MeanSquaredError: 0.4676 - loss: 0.4676 - val_MeanSquaredError: 0.4810 - val_loss: 0.4810\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - MeanSquaredError: 0.5403 - loss: 0.5403\n",
      "MSE:0.5206738114356995%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "md_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(8, input_shape = (8,), activation='relu'),\n",
    "    Dropout(.1),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    Dropout(.1),\n",
    "    tf.keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "\n",
    "md_3.compile(optimizer='adam', loss='mean_squared_error', metrics=['MeanSquaredError'])\n",
    "\n",
    "md_3.fit(x_train, y_train, epochs=20, validation_split=.1)\n",
    "\n",
    "loss, MSE = md_3.evaluate(x_test, y_test)\n",
    "print(f'MSE:{MSE}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 (3 points)\n",
    "\n",
    "Which of model would you use to predict median house value for California houses? Why? Be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would use model 2 because it has the lowest MSE out of the 3 models "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
