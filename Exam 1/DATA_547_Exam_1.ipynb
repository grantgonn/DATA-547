{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 (20 points) \n",
    "\n",
    "Please state **True** or **False** for the below statements.\n",
    "\n",
    "- (a) Tensors in TensorFlow can only hold numerical data types, such as integers or floats. \n",
    "\n",
    "- (b) A deep neural network with three hidden layers will always outperform a deep neural network with two hidden layers. \n",
    "\n",
    "- (c) CNNs are primarily used for image-related tasks but can also be applied to other domains like natural language processing (NLP) and time series data. \n",
    "\n",
    "- (d) The objective of the activation function in a neural network is to handle linearity in the network. \n",
    "\n",
    "- (e) `TensorFlow` can only run on `CPU`. \n",
    "\n",
    "- (f) `Dropout` is a technique that can help to prevent overfitting in neural networks. \n",
    "\n",
    "- (g) `TensorFlow` can only run on `GPU`. \n",
    "\n",
    "- (h) In a CNN, the convolutional layer is responsible for learning spatial hierarchies by applying filters that detect features such as edges, textures, and patterns. \n",
    "\n",
    "- (i) Pooling layers in CNNs increase the spatial dimensions of the input to gain more details about the data. \n",
    "\n",
    "- (j) In deep neural networks, increasing the number of hidden layers and `batch_size` will always improve model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. False\n",
    "\n",
    "b. False\n",
    "\n",
    "c. True\n",
    "\n",
    "d. False\n",
    "\n",
    "e. False\n",
    "\n",
    "f. True\n",
    "\n",
    "g. False\n",
    "\n",
    "h. True\n",
    "\n",
    "i. False\n",
    "\n",
    "j. False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 (5 points)\n",
    "\n",
    "How many neurons do you need in the output layer if you want to classify email into `spam` or `ham`? What activation function should you use in the output layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1, sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 (4 points)\n",
    "\n",
    "What is the main reason of increasing popularity of Deep Learning?\n",
    "\n",
    "- (a) The advances in deep learning algorithms and research.\n",
    "- (b) The availability of massive amounts of data for training deep learning algorithms.\n",
    "- (c) The dramatic increases in computer processing capabilities.\n",
    "- (d) All of the above.\n",
    "- (e) None of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 (5 points)\n",
    "\n",
    "What is the difference between `tf.Variable` and `tf.get_variable`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.variable is used to creat a new create a new variable while tf.get_variable can be used to create or return a variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 (4 points)\n",
    "\n",
    "`ReLU` is one of the most popular activation function in deep learning applications. Which of the following best describes the `ReLU` function?\n",
    "\n",
    "- (a) (-1, 1)\n",
    "- (b) (0, 5)\n",
    "- (c) (0, max)\n",
    "- (d) (-inf, inf)\n",
    "- (e) (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6 (4 points)\n",
    "\n",
    "What is a dense layer in a `TensorFlow` model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a layer of nurons where every nuron is connected to every nuron in the previous layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7 (5 points)\n",
    "\n",
    "What kind of features do the early layers of a CNN find? How about the later layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early layers detect low level details like edges, textures, and corners. The later layers detect higher level details such as parts of objects, and complex shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8 (4 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following statements best describe the purpose of the Pooling layer in a CNN model?\n",
    "\n",
    "- (a) To apply filters that detect spatial features like edges and textures.\n",
    "- (b) To reduce the spatial dimensions of the input and help control overfitting.\n",
    "- (c) To increase the number of neurons in the network for better learning capacity.\n",
    "- (d) To normalize the input data and ensure a consistent distribution of values.\n",
    "- (e) All of the above.\n",
    "- (f) None of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9 (5 points)\n",
    "\n",
    "What is data augmentation in CNN? Why is needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentations can be include geometric, color, noise addition, and cropping. This is needed reduce the chance of overfitting, increase dataset size, and improve generalization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 10 (4 points)\n",
    "\n",
    "In deep learning models, which of the following is the most appropriate choice for the output layer activation function in a regression task?\n",
    "\n",
    "- (a) Softmax \n",
    "- (b) ReLu\n",
    "- (c) Sigmoid\n",
    "- (d) Tanh\n",
    "- (e) All of the above\n",
    "- (f) None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11\n",
    "\n",
    "Consider the `train.csv` data file. These are the descriptions of most of the variables in this dataset:\n",
    "\n",
    "- `clonesize`: the average blueberry clone size in the field.\n",
    "- `honeybee`: honeybee density in the field.\n",
    "- `bumbles`: bumblebee density in the field.\n",
    "- `andrena`: andrena bee density in the field.\n",
    "- `osmia`: osmia bee density in the field.\n",
    "- `MaxOfUpperTRange`: the highest record of the upper band daily air temperature during the bloom season.\n",
    "- `MinOfUpperTRange`: the lowest record of the upper band daily air temperature.\n",
    "- `AverageOfUpperTRange`: the average of the upper band daily air temperature.\n",
    "- `MaxOfLowerTRange`: the highest record of the lower band daily air temperature.\n",
    "- `MinOfLowerTRange`: the lowest record of the lower band daily air temperature.\n",
    "- `AverageOfLowerTRange`: the average of the lower band daily air temperature.\n",
    "- `RainingDays`: the total number of days during the bloom season, each of which has precipitation larger than zero.\n",
    "- `AverageRainingDays`: the average of raining days of the entire bloom season.\n",
    "\n",
    "In this exercise, you will built a few deep learning networks to predict `yield`. \n",
    "\n",
    "### Exercise 11(a) (2 points)\n",
    "\n",
    "Load the following libraries.\n",
    "\n",
    "```\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11(b) (2 points)\n",
    "\n",
    "Read the `train.csv` data file and create a data frame called `df`. Make sure to use the `id` column as index. Hint: use `index_col='id'` in `pd.read_csv()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clonesize</th>\n",
       "      <th>honeybee</th>\n",
       "      <th>bumbles</th>\n",
       "      <th>andrena</th>\n",
       "      <th>osmia</th>\n",
       "      <th>MaxOfUpperTRange</th>\n",
       "      <th>MinOfUpperTRange</th>\n",
       "      <th>AverageOfUpperTRange</th>\n",
       "      <th>MaxOfLowerTRange</th>\n",
       "      <th>MinOfLowerTRange</th>\n",
       "      <th>AverageOfLowerTRange</th>\n",
       "      <th>RainingDays</th>\n",
       "      <th>AverageRainingDays</th>\n",
       "      <th>fruitset</th>\n",
       "      <th>fruitmass</th>\n",
       "      <th>seeds</th>\n",
       "      <th>yield</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>69.7</td>\n",
       "      <td>42.1</td>\n",
       "      <td>58.2</td>\n",
       "      <td>50.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>41.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.425011</td>\n",
       "      <td>0.417545</td>\n",
       "      <td>32.460887</td>\n",
       "      <td>4476.81146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>69.7</td>\n",
       "      <td>42.1</td>\n",
       "      <td>58.2</td>\n",
       "      <td>50.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>41.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.444908</td>\n",
       "      <td>0.422051</td>\n",
       "      <td>33.858317</td>\n",
       "      <td>5548.12201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>86.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>71.9</td>\n",
       "      <td>62.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.552927</td>\n",
       "      <td>0.470853</td>\n",
       "      <td>38.341781</td>\n",
       "      <td>6869.77760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.50</td>\n",
       "      <td>77.4</td>\n",
       "      <td>46.8</td>\n",
       "      <td>64.7</td>\n",
       "      <td>55.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.565976</td>\n",
       "      <td>0.478137</td>\n",
       "      <td>39.467561</td>\n",
       "      <td>6880.77590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>77.4</td>\n",
       "      <td>46.8</td>\n",
       "      <td>64.7</td>\n",
       "      <td>55.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.579677</td>\n",
       "      <td>0.494165</td>\n",
       "      <td>40.484512</td>\n",
       "      <td>7479.93417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clonesize  honeybee  bumbles  andrena  osmia  MaxOfUpperTRange  \\\n",
       "id                                                                   \n",
       "0        25.0      0.50     0.25     0.75   0.50              69.7   \n",
       "1        25.0      0.50     0.25     0.50   0.50              69.7   \n",
       "2        12.5      0.25     0.25     0.63   0.63              86.0   \n",
       "3        12.5      0.25     0.25     0.63   0.50              77.4   \n",
       "4        25.0      0.50     0.25     0.63   0.63              77.4   \n",
       "\n",
       "    MinOfUpperTRange  AverageOfUpperTRange  MaxOfLowerTRange  \\\n",
       "id                                                             \n",
       "0               42.1                  58.2              50.2   \n",
       "1               42.1                  58.2              50.2   \n",
       "2               52.0                  71.9              62.0   \n",
       "3               46.8                  64.7              55.8   \n",
       "4               46.8                  64.7              55.8   \n",
       "\n",
       "    MinOfLowerTRange  AverageOfLowerTRange  RainingDays  AverageRainingDays  \\\n",
       "id                                                                            \n",
       "0               24.3                  41.2         24.0                0.39   \n",
       "1               24.3                  41.2         24.0                0.39   \n",
       "2               30.0                  50.8         24.0                0.39   \n",
       "3               27.0                  45.8         24.0                0.39   \n",
       "4               27.0                  45.8         24.0                0.39   \n",
       "\n",
       "    fruitset  fruitmass      seeds       yield  \n",
       "id                                              \n",
       "0   0.425011   0.417545  32.460887  4476.81146  \n",
       "1   0.444908   0.422051  33.858317  5548.12201  \n",
       "2   0.552927   0.470853  38.341781  6869.77760  \n",
       "3   0.565976   0.478137  39.467561  6880.77590  \n",
       "4   0.579677   0.494165  40.484512  7479.93417  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', index_col='id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11(c) (3 points)\n",
    "\n",
    "Create a histogram of `yield`. Describe the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['yield'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11(d) (4 points)\n",
    "\n",
    "Define `yield` as the target feature, and the other features as the input features. Then, split the data into `train` (80%) and `test` (20%.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=['yield'], axis=1)\n",
    "y = df['yield']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11(e) (6 points)\n",
    "\n",
    "Build a neural network and evaluate it as follows:\n",
    "\n",
    "- Define a network with 2 layers of 32 neurons and `relu` as the activation function.\n",
    "- Compile the model with `optimizer=tf.keras.optimizers.Adam(learning_rate=0.1)`, and `loss='MeanAbsoluteError'`.\n",
    "- Build the model on the `train` data, with `epochs=30` and `validation_split=0.1`.\n",
    "- Evaluate the model in the `test` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmgma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1291.8309 - val_loss: 498.8000\n",
      "Epoch 2/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 561.9757 - val_loss: 484.2316\n",
      "Epoch 3/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 518.6812 - val_loss: 452.9629\n",
      "Epoch 4/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 522.2932 - val_loss: 507.4602\n",
      "Epoch 5/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 508.3509 - val_loss: 461.1484\n",
      "Epoch 6/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 530.3554 - val_loss: 444.1175\n",
      "Epoch 7/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 495.9526 - val_loss: 671.8853\n",
      "Epoch 8/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 529.4428 - val_loss: 500.9597\n",
      "Epoch 9/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 529.5688 - val_loss: 502.7916\n",
      "Epoch 10/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 502.2255 - val_loss: 469.2305\n",
      "Epoch 11/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 506.9015 - val_loss: 533.1132\n",
      "Epoch 12/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 473.1063 - val_loss: 637.4842\n",
      "Epoch 13/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 515.3922 - val_loss: 439.0902\n",
      "Epoch 14/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 504.1460 - val_loss: 487.9937\n",
      "Epoch 15/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 490.2659 - val_loss: 570.4399\n",
      "Epoch 16/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 491.0186 - val_loss: 436.4189\n",
      "Epoch 17/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 483.4851 - val_loss: 620.4177\n",
      "Epoch 18/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 496.0988 - val_loss: 448.4263\n",
      "Epoch 19/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 490.4941 - val_loss: 441.0488\n",
      "Epoch 20/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 468.7592 - val_loss: 465.7719\n",
      "Epoch 21/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 498.5073 - val_loss: 432.9393\n",
      "Epoch 22/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 481.3387 - val_loss: 445.5827\n",
      "Epoch 23/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 470.1422 - val_loss: 447.2281\n",
      "Epoch 24/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 487.2990 - val_loss: 528.7779\n",
      "Epoch 25/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 470.5301 - val_loss: 465.6123\n",
      "Epoch 26/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 481.1393 - val_loss: 459.0919\n",
      "Epoch 27/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 460.8821 - val_loss: 431.3206\n",
      "Epoch 28/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 460.6265 - val_loss: 497.6710\n",
      "Epoch 29/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 479.0077 - val_loss: 446.7081\n",
      "Epoch 30/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 464.7184 - val_loss: 448.7672\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - loss: 466.1308\n",
      "MAE:458.7793884277344\n"
     ]
    }
   ],
   "source": [
    "md_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, input_shape = (16,), activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "\n",
    "md_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), loss='MeanAbsoluteError')\n",
    "\n",
    "md_1.fit(x_train, y_train, epochs=30, validation_split=.1)\n",
    "\n",
    "MAE = md_1.evaluate(x_test, y_test)\n",
    "print(f'MAE:{MAE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11(f) (6 points)\n",
    "\n",
    "Build a neural network and evaluate it as follows:\n",
    "\n",
    "- Define a network with 2 layers of 32 neurons and `relu` as the activation function. Make sure to include `BatchNormalization()`\n",
    "before the first layer.\n",
    "- Compile the model with `optimizer=tf.keras.optimizers.Adam(learning_rate=0.1)`, and `loss='MeanAbsoluteError'`.\n",
    "- Build the model on the `train` data, with `epochs=30` and `validation_split=0.1`.\n",
    "- Evaluate the model in the `test` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmgma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1625.3939 - val_loss: 716.7899\n",
      "Epoch 2/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 564.2627 - val_loss: 438.0513\n",
      "Epoch 3/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 534.6022 - val_loss: 402.8105\n",
      "Epoch 4/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 592.7882 - val_loss: 468.3162\n",
      "Epoch 5/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 565.8142 - val_loss: 423.1418\n",
      "Epoch 6/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 537.4406 - val_loss: 406.3476\n",
      "Epoch 7/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 597.7081 - val_loss: 414.6617\n",
      "Epoch 8/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 532.3225 - val_loss: 429.1973\n",
      "Epoch 9/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 549.6802 - val_loss: 379.2713\n",
      "Epoch 10/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 510.8567 - val_loss: 391.8203\n",
      "Epoch 11/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 521.5026 - val_loss: 610.7589\n",
      "Epoch 12/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 504.3250 - val_loss: 405.3282\n",
      "Epoch 13/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 498.6111 - val_loss: 456.2329\n",
      "Epoch 14/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 530.4653 - val_loss: 453.0626\n",
      "Epoch 15/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 495.6796 - val_loss: 392.9260\n",
      "Epoch 16/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 507.3559 - val_loss: 487.4405\n",
      "Epoch 17/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 501.1981 - val_loss: 411.0101\n",
      "Epoch 18/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 506.1163 - val_loss: 440.6684\n",
      "Epoch 19/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 506.8909 - val_loss: 387.8546\n",
      "Epoch 20/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 483.1491 - val_loss: 416.7625\n",
      "Epoch 21/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 481.9622 - val_loss: 423.1436\n",
      "Epoch 22/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 479.1396 - val_loss: 643.6245\n",
      "Epoch 23/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 486.8111 - val_loss: 392.4523\n",
      "Epoch 24/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 479.3111 - val_loss: 419.2061\n",
      "Epoch 25/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 496.2142 - val_loss: 538.2067\n",
      "Epoch 26/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 485.2817 - val_loss: 392.5673\n",
      "Epoch 27/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 485.0890 - val_loss: 566.5403\n",
      "Epoch 28/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 469.8318 - val_loss: 394.6723\n",
      "Epoch 29/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 476.6759 - val_loss: 465.9555\n",
      "Epoch 30/30\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 481.8103 - val_loss: 391.4863\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - loss: 413.9207\n",
      "MAE:409.24285888671875\n"
     ]
    }
   ],
   "source": [
    "md_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, input_shape = (16,), activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "\n",
    "md_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), loss='MeanAbsoluteError')\n",
    "\n",
    "md_2.fit(x_train, y_train, epochs=30, validation_split=.1)\n",
    "\n",
    "MAE = md_2.evaluate(x_test, y_test)\n",
    "print(f'MAE:{MAE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11(g) (6 points)\n",
    "\n",
    "Build a neural network and evaluate it as follows:\n",
    "\n",
    "- Define a network with 2 layers of 32 neurons and `relu` as the activation function.\n",
    "- Compile the model with `optimizer=tf.keras.optimizers.Adam(learning_rate=0.1)`, and `loss='MeanAbsoluteError'`.\n",
    "- Build the model on the `train` data, with `epochs=30`, `batch_size=64`, and `validation_split=0.1`.\n",
    "- Evaluate the model in the `test` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmgma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1760.2091 - val_loss: 910.2842\n",
      "Epoch 2/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 567.8337 - val_loss: 457.6087\n",
      "Epoch 3/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 515.7010 - val_loss: 512.2730\n",
      "Epoch 4/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 486.1462 - val_loss: 654.0971\n",
      "Epoch 5/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 540.9712 - val_loss: 465.6857\n",
      "Epoch 6/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 491.4198 - val_loss: 684.5114\n",
      "Epoch 7/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 482.2625 - val_loss: 473.3403\n",
      "Epoch 8/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 476.8086 - val_loss: 486.0017\n",
      "Epoch 9/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 527.6116 - val_loss: 530.1783\n",
      "Epoch 10/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 508.5108 - val_loss: 633.1710\n",
      "Epoch 11/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 539.5466 - val_loss: 452.2710\n",
      "Epoch 12/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 494.5196 - val_loss: 470.2234\n",
      "Epoch 13/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 475.8971 - val_loss: 488.6772\n",
      "Epoch 14/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 486.1384 - val_loss: 532.6414\n",
      "Epoch 15/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 476.4449 - val_loss: 449.8235\n",
      "Epoch 16/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 482.0760 - val_loss: 581.8193\n",
      "Epoch 17/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 492.3522 - val_loss: 439.9760\n",
      "Epoch 18/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 491.9407 - val_loss: 543.5557\n",
      "Epoch 19/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 488.9168 - val_loss: 474.2314\n",
      "Epoch 20/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 483.0125 - val_loss: 475.1255\n",
      "Epoch 21/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 477.9840 - val_loss: 515.8320\n",
      "Epoch 22/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 482.3117 - val_loss: 447.8299\n",
      "Epoch 23/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 469.0135 - val_loss: 587.7267\n",
      "Epoch 24/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 471.3488 - val_loss: 497.5145\n",
      "Epoch 25/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 470.9731 - val_loss: 436.5053\n",
      "Epoch 26/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 499.2357 - val_loss: 465.6092\n",
      "Epoch 27/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 470.1667 - val_loss: 431.3899\n",
      "Epoch 28/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 470.6758 - val_loss: 498.3223\n",
      "Epoch 29/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 484.6107 - val_loss: 451.2371\n",
      "Epoch 30/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 458.0100 - val_loss: 475.9248\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - loss: 515.8814\n",
      "MAE:504.4548034667969\n"
     ]
    }
   ],
   "source": [
    "md_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, input_shape = (16,), activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "\n",
    "md_3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), loss='MeanAbsoluteError')\n",
    "\n",
    "md_3.fit(x_train, y_train, epochs=30, batch_size=64, validation_split=.1)\n",
    "\n",
    "MAE = md_3.evaluate(x_test, y_test)\n",
    "print(f'MAE:{MAE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11(h) (6 points)\n",
    "\n",
    "Build a neural network and evaluate it as follows:\n",
    "\n",
    "- Define a network with 2 layers of 32 neurons and `relu` as the activation function. Make sure to include `BatchNormalization()`\n",
    "before the first layer.\n",
    "- Compile the model with `optimizer=tf.keras.optimizers.Adam(learning_rate=0.1)`, and `loss='MeanAbsoluteError'`.\n",
    "- Build the model on the `train` data, with `epochs=30`, `batch_size=64`, and `validation_split=0.1`.\n",
    "- Evaluate the model in the `test` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmgma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1970.8140 - val_loss: 1084.6003\n",
      "Epoch 2/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 513.9568 - val_loss: 719.1730\n",
      "Epoch 3/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 529.4059 - val_loss: 452.5675\n",
      "Epoch 4/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 481.1037 - val_loss: 438.9317\n",
      "Epoch 5/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 466.1716 - val_loss: 723.2280\n",
      "Epoch 6/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 477.1494 - val_loss: 373.6543\n",
      "Epoch 7/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 532.0060 - val_loss: 609.5101\n",
      "Epoch 8/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 486.2460 - val_loss: 415.5696\n",
      "Epoch 9/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 485.2842 - val_loss: 390.3369\n",
      "Epoch 10/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 522.4205 - val_loss: 388.1635\n",
      "Epoch 11/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 448.4536 - val_loss: 373.2363\n",
      "Epoch 12/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 494.1020 - val_loss: 613.2523\n",
      "Epoch 13/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 473.1993 - val_loss: 487.5193\n",
      "Epoch 14/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 470.1736 - val_loss: 446.4244\n",
      "Epoch 15/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 452.2462 - val_loss: 538.8774\n",
      "Epoch 16/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 441.7088 - val_loss: 378.0183\n",
      "Epoch 17/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 481.4888 - val_loss: 464.0346\n",
      "Epoch 18/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 455.5686 - val_loss: 541.3812\n",
      "Epoch 19/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 454.4310 - val_loss: 364.9111\n",
      "Epoch 20/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 480.6633 - val_loss: 589.8261\n",
      "Epoch 21/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 440.4458 - val_loss: 389.1617\n",
      "Epoch 22/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 435.6357 - val_loss: 515.2620\n",
      "Epoch 23/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 489.6352 - val_loss: 423.9594\n",
      "Epoch 24/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 447.2748 - val_loss: 382.1224\n",
      "Epoch 25/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 437.4012 - val_loss: 423.2399\n",
      "Epoch 26/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 447.9306 - val_loss: 404.5240\n",
      "Epoch 27/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 457.4892 - val_loss: 383.3741\n",
      "Epoch 28/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 459.1013 - val_loss: 405.0703\n",
      "Epoch 29/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 444.4017 - val_loss: 376.7743\n",
      "Epoch 30/30\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 431.4435 - val_loss: 435.2527\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 463.2586\n",
      "MAE:461.1558532714844\n"
     ]
    }
   ],
   "source": [
    "md_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(32, input_shape = (16,), activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='relu')\n",
    "])\n",
    "\n",
    "md_4.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), loss='MeanAbsoluteError')\n",
    "\n",
    "md_4.fit(x_train, y_train, epochs=30, batch_size=64, validation_split=.1)\n",
    "\n",
    "MAE = md_4.evaluate(x_test, y_test)\n",
    "print(f'MAE:{MAE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11(i) (2 points)\n",
    "\n",
    "Using the results from parts 1(e) to 1(h), what model would use to predict `yield`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would use model 2 because it has the lowest MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 12\n",
    "\n",
    "In this exercise, we will practice how to use deep neural networks on image data. We will be using the popular [Fashion mnist](https://www.tensorflow.org/datasets/catalog/fashion_mnist), which consists of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image associated with a label from 10 classes. Our goal is to build a neural network model to predict the label of a given image. We will achieve this in the following exercises.\n",
    "\n",
    "### Exercise 12(a) (2 points)\n",
    "\n",
    "Load the below libraries.\n",
    "\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12(b) (2 points)\n",
    "\n",
    "Load the `fashion_mnist` data as follows:\n",
    "\n",
    "```\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12(c) (12 points)\n",
    "\n",
    "Build a CNN model as follows:\n",
    "\n",
    "- Change the digit labels to 0-1 encoding.\n",
    "- The CNN model should have the following layers in the given order:\n",
    "    - `Conv2D` with 32 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Conv2D` with 32 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Flatten`\n",
    "    - `Dense` with 128 neurons and `activation=relu`\n",
    "    - `Dense` with 10 neurons and `activation=softmax`\n",
    "- Compile the network with the following:\n",
    "    - `optimizer='adam'`\n",
    "    - `loss='categorical_crossentropy'`\n",
    "    - `metrics=['accuracy']`\n",
    "- Train the deep neural network with `epochs=50`, `batch_size=128`, and `validation_split=0.1`.\n",
    "- Evaluate the model on the `test` data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.7024 - loss: 2.0391 - val_accuracy: 0.8448 - val_loss: 0.4251\n",
      "Epoch 2/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8626 - loss: 0.3883 - val_accuracy: 0.8702 - val_loss: 0.3527\n",
      "Epoch 3/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8844 - loss: 0.3173 - val_accuracy: 0.8743 - val_loss: 0.3316\n",
      "Epoch 4/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8970 - loss: 0.2820 - val_accuracy: 0.8832 - val_loss: 0.3220\n",
      "Epoch 5/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9071 - loss: 0.2468 - val_accuracy: 0.8895 - val_loss: 0.3069\n",
      "Epoch 6/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9179 - loss: 0.2220 - val_accuracy: 0.8802 - val_loss: 0.3324\n",
      "Epoch 7/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9241 - loss: 0.2030 - val_accuracy: 0.8930 - val_loss: 0.3131\n",
      "Epoch 8/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9284 - loss: 0.1904 - val_accuracy: 0.8925 - val_loss: 0.3021\n",
      "Epoch 9/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9340 - loss: 0.1786 - val_accuracy: 0.8945 - val_loss: 0.2978\n",
      "Epoch 10/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9370 - loss: 0.1667 - val_accuracy: 0.8952 - val_loss: 0.2964\n",
      "Epoch 11/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9434 - loss: 0.1517 - val_accuracy: 0.8958 - val_loss: 0.3295\n",
      "Epoch 12/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9486 - loss: 0.1351 - val_accuracy: 0.8922 - val_loss: 0.3404\n",
      "Epoch 13/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9507 - loss: 0.1282 - val_accuracy: 0.8812 - val_loss: 0.3772\n",
      "Epoch 14/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9509 - loss: 0.1287 - val_accuracy: 0.8918 - val_loss: 0.3537\n",
      "Epoch 15/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9581 - loss: 0.1126 - val_accuracy: 0.8940 - val_loss: 0.3788\n",
      "Epoch 16/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9609 - loss: 0.1058 - val_accuracy: 0.8882 - val_loss: 0.4182\n",
      "Epoch 17/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9606 - loss: 0.1076 - val_accuracy: 0.8935 - val_loss: 0.4183\n",
      "Epoch 18/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9688 - loss: 0.0865 - val_accuracy: 0.8970 - val_loss: 0.4105\n",
      "Epoch 19/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9687 - loss: 0.0831 - val_accuracy: 0.8957 - val_loss: 0.4123\n",
      "Epoch 20/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9669 - loss: 0.0867 - val_accuracy: 0.8897 - val_loss: 0.4907\n",
      "Epoch 21/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9686 - loss: 0.0899 - val_accuracy: 0.8913 - val_loss: 0.4746\n",
      "Epoch 22/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9720 - loss: 0.0748 - val_accuracy: 0.8948 - val_loss: 0.4707\n",
      "Epoch 23/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9748 - loss: 0.0679 - val_accuracy: 0.8888 - val_loss: 0.5003\n",
      "Epoch 24/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9754 - loss: 0.0692 - val_accuracy: 0.8958 - val_loss: 0.5002\n",
      "Epoch 25/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9764 - loss: 0.0622 - val_accuracy: 0.8950 - val_loss: 0.5092\n",
      "Epoch 26/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9779 - loss: 0.0586 - val_accuracy: 0.8977 - val_loss: 0.5821\n",
      "Epoch 27/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9803 - loss: 0.0519 - val_accuracy: 0.8915 - val_loss: 0.5711\n",
      "Epoch 28/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9806 - loss: 0.0542 - val_accuracy: 0.8952 - val_loss: 0.5997\n",
      "Epoch 29/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9793 - loss: 0.0576 - val_accuracy: 0.8873 - val_loss: 0.6571\n",
      "Epoch 30/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9786 - loss: 0.0589 - val_accuracy: 0.8957 - val_loss: 0.5899\n",
      "Epoch 31/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9824 - loss: 0.0497 - val_accuracy: 0.8928 - val_loss: 0.6278\n",
      "Epoch 32/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9861 - loss: 0.0377 - val_accuracy: 0.8905 - val_loss: 0.6253\n",
      "Epoch 33/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9833 - loss: 0.0427 - val_accuracy: 0.8867 - val_loss: 0.6709\n",
      "Epoch 34/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9803 - loss: 0.0592 - val_accuracy: 0.8933 - val_loss: 0.7162\n",
      "Epoch 35/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9822 - loss: 0.0535 - val_accuracy: 0.8935 - val_loss: 0.6813\n",
      "Epoch 36/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9875 - loss: 0.0347 - val_accuracy: 0.8940 - val_loss: 0.7127\n",
      "Epoch 37/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9844 - loss: 0.0430 - val_accuracy: 0.8957 - val_loss: 0.7249\n",
      "Epoch 38/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9858 - loss: 0.0396 - val_accuracy: 0.8930 - val_loss: 0.7518\n",
      "Epoch 39/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9849 - loss: 0.0419 - val_accuracy: 0.8928 - val_loss: 0.7713\n",
      "Epoch 40/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9843 - loss: 0.0461 - val_accuracy: 0.8933 - val_loss: 0.7788\n",
      "Epoch 41/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9851 - loss: 0.0433 - val_accuracy: 0.8915 - val_loss: 0.7743\n",
      "Epoch 42/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9895 - loss: 0.0279 - val_accuracy: 0.8833 - val_loss: 0.8721\n",
      "Epoch 43/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9871 - loss: 0.0371 - val_accuracy: 0.8900 - val_loss: 0.8786\n",
      "Epoch 44/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9848 - loss: 0.0459 - val_accuracy: 0.8963 - val_loss: 0.7730\n",
      "Epoch 45/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9913 - loss: 0.0239 - val_accuracy: 0.8930 - val_loss: 0.8855\n",
      "Epoch 46/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9887 - loss: 0.0345 - val_accuracy: 0.8937 - val_loss: 0.8454\n",
      "Epoch 47/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9854 - loss: 0.0436 - val_accuracy: 0.8905 - val_loss: 0.9157\n",
      "Epoch 48/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9875 - loss: 0.0388 - val_accuracy: 0.8957 - val_loss: 0.8549\n",
      "Epoch 49/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9924 - loss: 0.0221 - val_accuracy: 0.8943 - val_loss: 0.8985\n",
      "Epoch 50/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9918 - loss: 0.0250 - val_accuracy: 0.8922 - val_loss: 0.8774\n",
      "0.890999972820282\n"
     ]
    }
   ],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "md1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "md1.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "md1.fit(X_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.1)\n",
    "\n",
    "test_loss, test_acc = md1.evaluate(X_test, y_test, verbose = 0)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12(d) (10 points)\n",
    "\n",
    "Build a CNN model as follows:\n",
    "\n",
    "- The CNN model should have the following layers in the given order:\n",
    "    - `Conv2D` with 32 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Conv2D` with 64 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Flatten`\n",
    "    - `Dense` with 128 neurons and `activation=relu`\n",
    "    - `Dense` with 10 neurons and `activation=softmax`\n",
    "- Compile the network with the following:\n",
    "    - `optimizer='adam'`\n",
    "    - `loss='categorical_crossentropy'`\n",
    "    - `metrics=['accuracy']`\n",
    "- Train the deep neural network with `epochs=50`, `batch_size=128`, and `validation_split=0.1`.\n",
    "- Evaluate the model on the `test` data set.\n",
    "\n",
    "Notice that there is no need to 0-1 encode the target labels (it was done in part 11(c)); you can go ahead and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmgma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.7053 - loss: 3.1526 - val_accuracy: 0.8510 - val_loss: 0.4084\n",
      "Epoch 2/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8664 - loss: 0.3673 - val_accuracy: 0.8697 - val_loss: 0.3578\n",
      "Epoch 3/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.8901 - loss: 0.3057 - val_accuracy: 0.8838 - val_loss: 0.3231\n",
      "Epoch 4/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9023 - loss: 0.2643 - val_accuracy: 0.8898 - val_loss: 0.3117\n",
      "Epoch 5/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9104 - loss: 0.2388 - val_accuracy: 0.8915 - val_loss: 0.3004\n",
      "Epoch 6/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9215 - loss: 0.2136 - val_accuracy: 0.8927 - val_loss: 0.3164\n",
      "Epoch 7/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9278 - loss: 0.2001 - val_accuracy: 0.8977 - val_loss: 0.2947\n",
      "Epoch 8/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9306 - loss: 0.1806 - val_accuracy: 0.8887 - val_loss: 0.3270\n",
      "Epoch 9/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9381 - loss: 0.1706 - val_accuracy: 0.8980 - val_loss: 0.3086\n",
      "Epoch 10/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9412 - loss: 0.1563 - val_accuracy: 0.8963 - val_loss: 0.3020\n",
      "Epoch 11/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9458 - loss: 0.1450 - val_accuracy: 0.8932 - val_loss: 0.3412\n",
      "Epoch 12/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9500 - loss: 0.1352 - val_accuracy: 0.8965 - val_loss: 0.3404\n",
      "Epoch 13/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9522 - loss: 0.1251 - val_accuracy: 0.8972 - val_loss: 0.3544\n",
      "Epoch 14/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9581 - loss: 0.1141 - val_accuracy: 0.8938 - val_loss: 0.3688\n",
      "Epoch 15/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9570 - loss: 0.1105 - val_accuracy: 0.8965 - val_loss: 0.3778\n",
      "Epoch 16/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9625 - loss: 0.1018 - val_accuracy: 0.8965 - val_loss: 0.3805\n",
      "Epoch 17/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.9598 - loss: 0.1057 - val_accuracy: 0.8935 - val_loss: 0.4131\n",
      "Epoch 18/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9668 - loss: 0.0863 - val_accuracy: 0.9037 - val_loss: 0.3616\n",
      "Epoch 19/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9700 - loss: 0.0808 - val_accuracy: 0.8935 - val_loss: 0.4069\n",
      "Epoch 20/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9752 - loss: 0.0692 - val_accuracy: 0.8987 - val_loss: 0.4163\n",
      "Epoch 21/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9698 - loss: 0.0853 - val_accuracy: 0.9008 - val_loss: 0.4397\n",
      "Epoch 22/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9749 - loss: 0.0718 - val_accuracy: 0.8938 - val_loss: 0.4846\n",
      "Epoch 23/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9769 - loss: 0.0627 - val_accuracy: 0.8963 - val_loss: 0.4749\n",
      "Epoch 24/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9771 - loss: 0.0624 - val_accuracy: 0.8975 - val_loss: 0.4697\n",
      "Epoch 25/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9766 - loss: 0.0649 - val_accuracy: 0.8955 - val_loss: 0.5171\n",
      "Epoch 26/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9803 - loss: 0.0525 - val_accuracy: 0.8965 - val_loss: 0.5188\n",
      "Epoch 27/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9828 - loss: 0.0502 - val_accuracy: 0.9015 - val_loss: 0.5482\n",
      "Epoch 28/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9818 - loss: 0.0518 - val_accuracy: 0.8920 - val_loss: 0.6025\n",
      "Epoch 29/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9794 - loss: 0.0580 - val_accuracy: 0.8965 - val_loss: 0.5714\n",
      "Epoch 30/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9810 - loss: 0.0541 - val_accuracy: 0.8958 - val_loss: 0.6473\n",
      "Epoch 31/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9844 - loss: 0.0450 - val_accuracy: 0.8955 - val_loss: 0.5650\n",
      "Epoch 32/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9843 - loss: 0.0421 - val_accuracy: 0.8920 - val_loss: 0.6495\n",
      "Epoch 33/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9836 - loss: 0.0446 - val_accuracy: 0.8935 - val_loss: 0.6165\n",
      "Epoch 34/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9837 - loss: 0.0460 - val_accuracy: 0.8985 - val_loss: 0.6876\n",
      "Epoch 35/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9877 - loss: 0.0328 - val_accuracy: 0.8968 - val_loss: 0.6514\n",
      "Epoch 36/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9802 - loss: 0.0603 - val_accuracy: 0.9015 - val_loss: 0.7119\n",
      "Epoch 37/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9882 - loss: 0.0337 - val_accuracy: 0.9013 - val_loss: 0.6573\n",
      "Epoch 38/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9890 - loss: 0.0312 - val_accuracy: 0.8902 - val_loss: 0.7274\n",
      "Epoch 39/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9853 - loss: 0.0423 - val_accuracy: 0.8975 - val_loss: 0.7637\n",
      "Epoch 40/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9854 - loss: 0.0473 - val_accuracy: 0.8970 - val_loss: 0.7437\n",
      "Epoch 41/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9872 - loss: 0.0377 - val_accuracy: 0.9043 - val_loss: 0.7297\n",
      "Epoch 42/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9910 - loss: 0.0258 - val_accuracy: 0.8992 - val_loss: 0.7840\n",
      "Epoch 43/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9880 - loss: 0.0371 - val_accuracy: 0.8930 - val_loss: 0.7267\n",
      "Epoch 44/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9913 - loss: 0.0272 - val_accuracy: 0.8952 - val_loss: 0.8138\n",
      "Epoch 45/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9897 - loss: 0.0307 - val_accuracy: 0.8923 - val_loss: 0.8505\n",
      "Epoch 46/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9870 - loss: 0.0393 - val_accuracy: 0.8955 - val_loss: 0.8505\n",
      "Epoch 47/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9895 - loss: 0.0330 - val_accuracy: 0.9017 - val_loss: 0.8213\n",
      "Epoch 48/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9929 - loss: 0.0200 - val_accuracy: 0.8908 - val_loss: 0.9408\n",
      "Epoch 49/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9876 - loss: 0.0394 - val_accuracy: 0.8965 - val_loss: 0.8922\n",
      "Epoch 50/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9888 - loss: 0.0348 - val_accuracy: 0.8980 - val_loss: 0.8175\n",
      "0.8981000185012817\n"
     ]
    }
   ],
   "source": [
    "md2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "md2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "md2.fit(X_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.1)\n",
    "\n",
    "test_loss, test_acc = md2.evaluate(X_test, y_test, verbose = 0)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12(e) (10 points)\n",
    "\n",
    "Build a CNN model as follows:\n",
    "\n",
    "- The CNN model should have the following layers in the given order:\n",
    "    - `Conv2D` with 64 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Conv2D` with 64 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Flatten`\n",
    "    - `Dense` with 128 neurons and `activation=relu`\n",
    "    - `Dense` with 10 neurons and `activation=softmax`\n",
    "- Compile the network with the following:\n",
    "    - `optimizer='adam'`\n",
    "    - `loss='categorical_crossentropy'`\n",
    "    - `metrics=['accuracy']`\n",
    "- Train the deep neural network with `epochs=50`, `batch_size=128`, and `validation_split=0.1`.\n",
    "- Evaluate the model on the `test` data set.\n",
    "\n",
    "Notice that there is no need to 0-1 encode the target labels (it was done in part 11(c)); you can go ahead and train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmgma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.7026 - loss: 3.3537 - val_accuracy: 0.8450 - val_loss: 0.4142\n",
      "Epoch 2/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.8656 - loss: 0.3727 - val_accuracy: 0.8715 - val_loss: 0.3542\n",
      "Epoch 3/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.8848 - loss: 0.3091 - val_accuracy: 0.8778 - val_loss: 0.3519\n",
      "Epoch 4/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.8967 - loss: 0.2784 - val_accuracy: 0.8897 - val_loss: 0.3127\n",
      "Epoch 5/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9075 - loss: 0.2476 - val_accuracy: 0.8877 - val_loss: 0.2989\n",
      "Epoch 6/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9151 - loss: 0.2289 - val_accuracy: 0.8937 - val_loss: 0.3042\n",
      "Epoch 7/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9187 - loss: 0.2128 - val_accuracy: 0.8873 - val_loss: 0.3032\n",
      "Epoch 8/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9271 - loss: 0.1942 - val_accuracy: 0.8925 - val_loss: 0.3026\n",
      "Epoch 9/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9325 - loss: 0.1806 - val_accuracy: 0.8970 - val_loss: 0.2918\n",
      "Epoch 10/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9359 - loss: 0.1686 - val_accuracy: 0.8955 - val_loss: 0.3146\n",
      "Epoch 11/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9394 - loss: 0.1593 - val_accuracy: 0.8963 - val_loss: 0.3168\n",
      "Epoch 12/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.9428 - loss: 0.1530 - val_accuracy: 0.8963 - val_loss: 0.3449\n",
      "Epoch 13/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.9435 - loss: 0.1444 - val_accuracy: 0.8942 - val_loss: 0.3366\n",
      "Epoch 14/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.9496 - loss: 0.1339 - val_accuracy: 0.8905 - val_loss: 0.3412\n",
      "Epoch 15/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9536 - loss: 0.1231 - val_accuracy: 0.8988 - val_loss: 0.3174\n",
      "Epoch 16/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9563 - loss: 0.1164 - val_accuracy: 0.8952 - val_loss: 0.3469\n",
      "Epoch 17/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9584 - loss: 0.1095 - val_accuracy: 0.8977 - val_loss: 0.3555\n",
      "Epoch 18/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9604 - loss: 0.1039 - val_accuracy: 0.9002 - val_loss: 0.3830\n",
      "Epoch 19/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9616 - loss: 0.1008 - val_accuracy: 0.8985 - val_loss: 0.3814\n",
      "Epoch 20/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9656 - loss: 0.0954 - val_accuracy: 0.8987 - val_loss: 0.4155\n",
      "Epoch 21/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9685 - loss: 0.0823 - val_accuracy: 0.8968 - val_loss: 0.4690\n",
      "Epoch 22/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9711 - loss: 0.0762 - val_accuracy: 0.9012 - val_loss: 0.4763\n",
      "Epoch 23/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9684 - loss: 0.0848 - val_accuracy: 0.8950 - val_loss: 0.4499\n",
      "Epoch 24/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9707 - loss: 0.0777 - val_accuracy: 0.9017 - val_loss: 0.5014\n",
      "Epoch 25/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9736 - loss: 0.0711 - val_accuracy: 0.8980 - val_loss: 0.5094\n",
      "Epoch 26/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9716 - loss: 0.0758 - val_accuracy: 0.8977 - val_loss: 0.4757\n",
      "Epoch 27/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9761 - loss: 0.0640 - val_accuracy: 0.8973 - val_loss: 0.5029\n",
      "Epoch 28/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9771 - loss: 0.0625 - val_accuracy: 0.9033 - val_loss: 0.5663\n",
      "Epoch 29/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9778 - loss: 0.0619 - val_accuracy: 0.8985 - val_loss: 0.5343\n",
      "Epoch 30/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9800 - loss: 0.0515 - val_accuracy: 0.8960 - val_loss: 0.6046\n",
      "Epoch 31/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9804 - loss: 0.0521 - val_accuracy: 0.8947 - val_loss: 0.6264\n",
      "Epoch 32/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9775 - loss: 0.0610 - val_accuracy: 0.8985 - val_loss: 0.6522\n",
      "Epoch 33/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9815 - loss: 0.0485 - val_accuracy: 0.9050 - val_loss: 0.5928\n",
      "Epoch 34/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9839 - loss: 0.0456 - val_accuracy: 0.8987 - val_loss: 0.5876\n",
      "Epoch 35/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9826 - loss: 0.0485 - val_accuracy: 0.8973 - val_loss: 0.6337\n",
      "Epoch 36/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9855 - loss: 0.0405 - val_accuracy: 0.9003 - val_loss: 0.6763\n",
      "Epoch 37/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9841 - loss: 0.0453 - val_accuracy: 0.8998 - val_loss: 0.6121\n",
      "Epoch 38/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9882 - loss: 0.0336 - val_accuracy: 0.8988 - val_loss: 0.7041\n",
      "Epoch 39/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9862 - loss: 0.0416 - val_accuracy: 0.8980 - val_loss: 0.6889\n",
      "Epoch 40/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9823 - loss: 0.0522 - val_accuracy: 0.9003 - val_loss: 0.7218\n",
      "Epoch 41/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9874 - loss: 0.0379 - val_accuracy: 0.8947 - val_loss: 0.7801\n",
      "Epoch 42/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9857 - loss: 0.0469 - val_accuracy: 0.8982 - val_loss: 0.8159\n",
      "Epoch 43/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9885 - loss: 0.0321 - val_accuracy: 0.8960 - val_loss: 0.7596\n",
      "Epoch 44/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9880 - loss: 0.0346 - val_accuracy: 0.8978 - val_loss: 0.7667\n",
      "Epoch 45/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.9877 - loss: 0.0362 - val_accuracy: 0.9018 - val_loss: 0.8514\n",
      "Epoch 46/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9862 - loss: 0.0387 - val_accuracy: 0.8977 - val_loss: 0.8286\n",
      "Epoch 47/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9892 - loss: 0.0297 - val_accuracy: 0.8997 - val_loss: 0.8105\n",
      "Epoch 48/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9889 - loss: 0.0329 - val_accuracy: 0.8977 - val_loss: 0.9090\n",
      "Epoch 49/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9897 - loss: 0.0318 - val_accuracy: 0.8882 - val_loss: 0.8600\n",
      "Epoch 50/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9862 - loss: 0.0415 - val_accuracy: 0.8975 - val_loss: 0.9353\n",
      "0.8946999907493591\n"
     ]
    }
   ],
   "source": [
    "md3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "md3.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "md3.fit(X_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.1)\n",
    "\n",
    "test_loss, test_acc = md3.evaluate(X_test, y_test, verbose = 0)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12(f) (15 points)\n",
    "\n",
    "Using the best model from parts 1(c) to 1(e), and `ImageDataGenerator` from `TensorFlow` augment the `fahion_mnist` data. Consider the below configuration to augment the `fashion_mnist` data set.\n",
    "\n",
    "```\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,       # Randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,   # Randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # Randomly shift images vertically (fraction of total height)\n",
    "    zoom_range=0.1,           # Randomly zoom images by up to 10%\n",
    "    horizontal_flip=False,   # Not flipping \n",
    ")\n",
    "```\n",
    "\n",
    "Reload the `fashion_mnist` data set, re-train the best model from parts 1(c) to 1(e) and augment the data with `datagen`. Report the accuracy on the `test` data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmgma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\gmgma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 44ms/step - accuracy: 0.6207 - loss: 2.1947 - val_accuracy: 0.8039 - val_loss: 0.5517\n",
      "Epoch 2/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.7917 - loss: 0.5481 - val_accuracy: 0.8364 - val_loss: 0.4447\n",
      "Epoch 3/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8130 - loss: 0.4944 - val_accuracy: 0.8265 - val_loss: 0.4904\n",
      "Epoch 4/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.8238 - loss: 0.4676 - val_accuracy: 0.8443 - val_loss: 0.4252\n",
      "Epoch 5/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8312 - loss: 0.4390 - val_accuracy: 0.8596 - val_loss: 0.3867\n",
      "Epoch 6/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.8395 - loss: 0.4249 - val_accuracy: 0.8495 - val_loss: 0.4298\n",
      "Epoch 7/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8416 - loss: 0.4154 - val_accuracy: 0.8567 - val_loss: 0.3928\n",
      "Epoch 8/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8538 - loss: 0.3909 - val_accuracy: 0.8708 - val_loss: 0.3736\n",
      "Epoch 9/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 46ms/step - accuracy: 0.8540 - loss: 0.3877 - val_accuracy: 0.8615 - val_loss: 0.3763\n",
      "Epoch 10/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.8588 - loss: 0.3796 - val_accuracy: 0.8712 - val_loss: 0.3670\n",
      "Epoch 11/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8614 - loss: 0.3734 - val_accuracy: 0.8796 - val_loss: 0.3430\n",
      "Epoch 12/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8647 - loss: 0.3587 - val_accuracy: 0.8714 - val_loss: 0.3646\n",
      "Epoch 13/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8675 - loss: 0.3593 - val_accuracy: 0.8770 - val_loss: 0.3408\n",
      "Epoch 14/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8706 - loss: 0.3484 - val_accuracy: 0.8809 - val_loss: 0.3267\n",
      "Epoch 15/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8712 - loss: 0.3441 - val_accuracy: 0.8724 - val_loss: 0.3515\n",
      "Epoch 16/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8704 - loss: 0.3430 - val_accuracy: 0.8770 - val_loss: 0.3454\n",
      "Epoch 17/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8710 - loss: 0.3369 - val_accuracy: 0.8777 - val_loss: 0.3582\n",
      "Epoch 18/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.8736 - loss: 0.3373 - val_accuracy: 0.8824 - val_loss: 0.3205\n",
      "Epoch 19/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8744 - loss: 0.3331 - val_accuracy: 0.8731 - val_loss: 0.3640\n",
      "Epoch 20/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8765 - loss: 0.3274 - val_accuracy: 0.8850 - val_loss: 0.3175\n",
      "Epoch 21/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.8796 - loss: 0.3232 - val_accuracy: 0.8744 - val_loss: 0.3477\n",
      "Epoch 22/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8789 - loss: 0.3218 - val_accuracy: 0.8855 - val_loss: 0.3217\n",
      "Epoch 23/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8799 - loss: 0.3177 - val_accuracy: 0.8881 - val_loss: 0.3113\n",
      "Epoch 24/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.8809 - loss: 0.3146 - val_accuracy: 0.8825 - val_loss: 0.3284\n",
      "Epoch 25/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8806 - loss: 0.3164 - val_accuracy: 0.8782 - val_loss: 0.3372\n",
      "Epoch 26/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8820 - loss: 0.3101 - val_accuracy: 0.8841 - val_loss: 0.3162\n",
      "Epoch 27/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 46ms/step - accuracy: 0.8834 - loss: 0.3112 - val_accuracy: 0.8858 - val_loss: 0.3337\n",
      "Epoch 28/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 46ms/step - accuracy: 0.8830 - loss: 0.3134 - val_accuracy: 0.8851 - val_loss: 0.3359\n",
      "Epoch 29/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8825 - loss: 0.3094 - val_accuracy: 0.8840 - val_loss: 0.3308\n",
      "Epoch 30/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8854 - loss: 0.3052 - val_accuracy: 0.8868 - val_loss: 0.3192\n",
      "Epoch 31/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.8870 - loss: 0.3026 - val_accuracy: 0.8876 - val_loss: 0.3156\n",
      "Epoch 32/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.8892 - loss: 0.2961 - val_accuracy: 0.8873 - val_loss: 0.3074\n",
      "Epoch 33/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8899 - loss: 0.2979 - val_accuracy: 0.8907 - val_loss: 0.3164\n",
      "Epoch 34/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8869 - loss: 0.3004 - val_accuracy: 0.8870 - val_loss: 0.3276\n",
      "Epoch 35/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8882 - loss: 0.2958 - val_accuracy: 0.8893 - val_loss: 0.3194\n",
      "Epoch 36/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8885 - loss: 0.2964 - val_accuracy: 0.8854 - val_loss: 0.3297\n",
      "Epoch 37/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8901 - loss: 0.2963 - val_accuracy: 0.8958 - val_loss: 0.3049\n",
      "Epoch 38/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8909 - loss: 0.2918 - val_accuracy: 0.8866 - val_loss: 0.3177\n",
      "Epoch 39/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8922 - loss: 0.2893 - val_accuracy: 0.8789 - val_loss: 0.3487\n",
      "Epoch 40/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.8930 - loss: 0.2876 - val_accuracy: 0.8868 - val_loss: 0.3411\n",
      "Epoch 41/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8896 - loss: 0.2993 - val_accuracy: 0.8888 - val_loss: 0.3314\n",
      "Epoch 42/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8924 - loss: 0.2896 - val_accuracy: 0.8936 - val_loss: 0.3147\n",
      "Epoch 43/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.8912 - loss: 0.2908 - val_accuracy: 0.8921 - val_loss: 0.3126\n",
      "Epoch 44/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8938 - loss: 0.2872 - val_accuracy: 0.8917 - val_loss: 0.3165\n",
      "Epoch 45/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.8935 - loss: 0.2843 - val_accuracy: 0.8954 - val_loss: 0.3068\n",
      "Epoch 46/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8940 - loss: 0.2830 - val_accuracy: 0.8956 - val_loss: 0.3135\n",
      "Epoch 47/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.8937 - loss: 0.2836 - val_accuracy: 0.8986 - val_loss: 0.2995\n",
      "Epoch 48/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8924 - loss: 0.2861 - val_accuracy: 0.8878 - val_loss: 0.3212\n",
      "Epoch 49/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.8949 - loss: 0.2811 - val_accuracy: 0.8918 - val_loss: 0.3147\n",
      "Epoch 50/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.8939 - loss: 0.2776 - val_accuracy: 0.8946 - val_loss: 0.3022\n",
      "0.894599974155426\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# Define the data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,       # Randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,   # Randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # Randomly shift images vertically (fraction of total height)\n",
    "    zoom_range=0.1,           # Randomly zoom images by up to 10%\n",
    "    horizontal_flip=False,   # Not flipping \n",
    ")\n",
    "\n",
    "\n",
    "md4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "md4.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "md4.fit(datagen.flow(X_train, y_train, batch_size=128), epochs=50, validation_data=(X_test, y_test))\n",
    "\n",
    "test_loss, test_acc = md4.evaluate(X_test, y_test, verbose = 0)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12(g) (2 points)\n",
    "\n",
    "Did the augmentation boost the model performance? Please, be specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My best model prior to augmentaion was model 2 with .898 accuracy. Model 4 with augmentation had an accuracy of .894 so augmentation did not improve the performace of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
