{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 \n",
    "\n",
    "In this exercise, we will keep practicing Convolutional Neural Network (CNN) to predict digit labels on the popular `mnist` data set.\n",
    "\n",
    "### Exercise 1(a) (3 points)\n",
    "\n",
    "Load the `mnist` data as `train` and `test` data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(b) (12 points)\n",
    "\n",
    "Build a CNN model as follows:\n",
    "\n",
    "- Change the digit labels to 0-1 encoding.\n",
    "- The CNN model should have the following layers in the given order:\n",
    "    - `Conv2D` with 32 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Conv2D` with 64 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Flatten`\n",
    "    - `Dense` with 128 neurons and `activation=relu`\n",
    "    - `Dense` with 10 neurons and `activation=softmax`\n",
    "- Evaluate the model on the `test` data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.7832 - loss: 4.6491 - val_accuracy: 0.9741 - val_loss: 0.0901\n",
      "Epoch 2/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.9761 - loss: 0.0773 - val_accuracy: 0.9819 - val_loss: 0.0641\n",
      "Epoch 3/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9869 - loss: 0.0428 - val_accuracy: 0.9803 - val_loss: 0.0695\n",
      "Epoch 4/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9911 - loss: 0.0304 - val_accuracy: 0.9838 - val_loss: 0.0581\n",
      "Epoch 5/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9918 - loss: 0.0249 - val_accuracy: 0.9831 - val_loss: 0.0664\n",
      "Epoch 6/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9923 - loss: 0.0247 - val_accuracy: 0.9852 - val_loss: 0.0604\n",
      "Epoch 7/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9935 - loss: 0.0177 - val_accuracy: 0.9840 - val_loss: 0.0694\n",
      "Epoch 8/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9936 - loss: 0.0203 - val_accuracy: 0.9840 - val_loss: 0.0734\n",
      "Epoch 9/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9950 - loss: 0.0151 - val_accuracy: 0.9858 - val_loss: 0.0644\n",
      "Epoch 10/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9945 - loss: 0.0161 - val_accuracy: 0.9852 - val_loss: 0.0733\n",
      "Epoch 11/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9954 - loss: 0.0143 - val_accuracy: 0.9844 - val_loss: 0.0776\n",
      "Epoch 12/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9964 - loss: 0.0113 - val_accuracy: 0.9857 - val_loss: 0.0754\n",
      "Epoch 13/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9948 - loss: 0.0176 - val_accuracy: 0.9852 - val_loss: 0.0709\n",
      "Epoch 14/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9961 - loss: 0.0118 - val_accuracy: 0.9865 - val_loss: 0.0711\n",
      "Epoch 15/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9958 - loss: 0.0124 - val_accuracy: 0.9850 - val_loss: 0.0797\n",
      "Epoch 16/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9949 - loss: 0.0163 - val_accuracy: 0.9860 - val_loss: 0.0786\n",
      "Epoch 17/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9968 - loss: 0.0095 - val_accuracy: 0.9842 - val_loss: 0.0903\n",
      "Epoch 18/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9962 - loss: 0.0119 - val_accuracy: 0.9865 - val_loss: 0.0713\n",
      "Epoch 19/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9970 - loss: 0.0081 - val_accuracy: 0.9866 - val_loss: 0.0831\n",
      "Epoch 20/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9960 - loss: 0.0119 - val_accuracy: 0.9833 - val_loss: 0.0951\n",
      "Epoch 21/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9967 - loss: 0.0124 - val_accuracy: 0.9878 - val_loss: 0.0725\n",
      "Epoch 22/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9981 - loss: 0.0062 - val_accuracy: 0.9862 - val_loss: 0.0919\n",
      "Epoch 23/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9968 - loss: 0.0105 - val_accuracy: 0.9829 - val_loss: 0.1095\n",
      "Epoch 24/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9966 - loss: 0.0120 - val_accuracy: 0.9882 - val_loss: 0.0839\n",
      "Epoch 25/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9977 - loss: 0.0083 - val_accuracy: 0.9841 - val_loss: 0.0970\n",
      "Epoch 26/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9984 - loss: 0.0063 - val_accuracy: 0.9881 - val_loss: 0.0721\n",
      "Epoch 27/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9980 - loss: 0.0065 - val_accuracy: 0.9874 - val_loss: 0.0763\n",
      "Epoch 28/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9973 - loss: 0.0098 - val_accuracy: 0.9871 - val_loss: 0.0870\n",
      "Epoch 29/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9976 - loss: 0.0092 - val_accuracy: 0.9880 - val_loss: 0.0877\n",
      "Epoch 30/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9985 - loss: 0.0051 - val_accuracy: 0.9874 - val_loss: 0.0893\n",
      "Epoch 31/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9986 - loss: 0.0052 - val_accuracy: 0.9823 - val_loss: 0.1426\n",
      "Epoch 32/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9949 - loss: 0.0212 - val_accuracy: 0.9868 - val_loss: 0.0953\n",
      "Epoch 33/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9982 - loss: 0.0065 - val_accuracy: 0.9867 - val_loss: 0.0897\n",
      "Epoch 34/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.9868 - val_loss: 0.0910\n",
      "Epoch 35/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9978 - loss: 0.0080 - val_accuracy: 0.9853 - val_loss: 0.1119\n",
      "Epoch 36/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9976 - loss: 0.0096 - val_accuracy: 0.9871 - val_loss: 0.1021\n",
      "Epoch 37/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 0.9874 - val_loss: 0.0889\n",
      "Epoch 38/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9878 - val_loss: 0.1031\n",
      "Epoch 39/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9983 - loss: 0.0064 - val_accuracy: 0.9849 - val_loss: 0.1277\n",
      "Epoch 40/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9978 - loss: 0.0086 - val_accuracy: 0.9887 - val_loss: 0.0978\n",
      "Epoch 41/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9982 - loss: 0.0075 - val_accuracy: 0.9877 - val_loss: 0.1103\n",
      "Epoch 42/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9988 - loss: 0.0058 - val_accuracy: 0.9878 - val_loss: 0.1026\n",
      "Epoch 43/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9982 - loss: 0.0075 - val_accuracy: 0.9884 - val_loss: 0.1065\n",
      "Epoch 44/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9980 - loss: 0.0100 - val_accuracy: 0.9895 - val_loss: 0.1063\n",
      "Epoch 45/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9988 - loss: 0.0053 - val_accuracy: 0.9899 - val_loss: 0.1061\n",
      "Epoch 46/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9986 - loss: 0.0055 - val_accuracy: 0.9867 - val_loss: 0.1331\n",
      "Epoch 47/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9985 - loss: 0.0049 - val_accuracy: 0.9887 - val_loss: 0.1179\n",
      "Epoch 48/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9988 - loss: 0.0058 - val_accuracy: 0.9877 - val_loss: 0.1406\n",
      "Epoch 49/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9993 - loss: 0.0040 - val_accuracy: 0.9873 - val_loss: 0.1202\n",
      "Epoch 50/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9982 - loss: 0.0098 - val_accuracy: 0.9862 - val_loss: 0.1491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x217bcd1ca00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "md1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "md1.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "md1.fit(x_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9858999848365784\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = md1.evaluate(x_test, y_test, verbose = 0)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 \n",
    "\n",
    "In this exercise, we will practive data augmentation concepts to boost the performance of CNN models.\n",
    "\n",
    "## Exercise 2(a) (10 points)\n",
    "\n",
    "Using the `ImageDataGenerator` from `TensorFlow` augment the `mnist` data. Consider the below configuration to augment the `mnist` data set.\n",
    "\n",
    "```\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,       # Randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,   # Randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # Randomly shift images vertically (fraction of total height)\n",
    "    zoom_range=0.1,           # Randomly zoom images by up to 10%\n",
    "    horizontal_flip=False,   # Not flipping since MNIST digits should not be flipped\n",
    ")\n",
    "```\n",
    "\n",
    "Reload the `mnist` data set, apply the `datagen` to a few of the images, and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "\n",
    "# Define the data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,       # Randomly rotate images in the range (degrees, 0 to 20)\n",
    "    width_shift_range=0.1,   # Randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # Randomly shift images vertically (fraction of total height)\n",
    "    zoom_range=0.1,           # Randomly zoom images by up to 10%\n",
    "    horizontal_flip=False,   # Not flipping since MNIST digits should not be flipped\n",
    ")\n",
    "\n",
    "# fir generator\n",
    "datagen.fit(x_train)\n",
    "\n",
    "def visualize_augmentation(original_img):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    \n",
    "    plt.subplot(1,5,1)\n",
    "    \n",
    "    plt.imshow(original_img.squeeze(), cmap='grey')\n",
    "    plt.title('original')\n",
    "    \n",
    "    for i in range(4):\n",
    "        augmented_img = datagen.random_transform(original_img)\n",
    "        \n",
    "        plt.subplot(1,5,i+2)\n",
    "        plt.imshow(augmented_img.squeeze(), cmap='grey')\n",
    "        plt.title(f'augmented image {i+1}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_img = x_train[2]\n",
    "\n",
    "visualize_augmentation(original_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2(b) (15 points)\n",
    "\n",
    "Apply the data augmentation from part 2(a) to the model from part 1(b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmgma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 44ms/step - accuracy: 0.7076 - loss: 3.0846 - val_accuracy: 0.9741 - val_loss: 0.0805\n",
      "Epoch 2/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.9487 - loss: 0.1656 - val_accuracy: 0.9778 - val_loss: 0.0730\n",
      "Epoch 3/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.9616 - loss: 0.1233 - val_accuracy: 0.9825 - val_loss: 0.0522\n",
      "Epoch 4/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9695 - loss: 0.0951 - val_accuracy: 0.9865 - val_loss: 0.0426\n",
      "Epoch 5/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.9732 - loss: 0.0883 - val_accuracy: 0.9784 - val_loss: 0.0730\n",
      "Epoch 6/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9768 - loss: 0.0740 - val_accuracy: 0.9848 - val_loss: 0.0525\n",
      "Epoch 7/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9780 - loss: 0.0711 - val_accuracy: 0.9888 - val_loss: 0.0350\n",
      "Epoch 8/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9792 - loss: 0.0661 - val_accuracy: 0.9879 - val_loss: 0.0381\n",
      "Epoch 9/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9802 - loss: 0.0625 - val_accuracy: 0.9904 - val_loss: 0.0295\n",
      "Epoch 10/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9817 - loss: 0.0608 - val_accuracy: 0.9898 - val_loss: 0.0327\n",
      "Epoch 11/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.9827 - loss: 0.0566 - val_accuracy: 0.9889 - val_loss: 0.0360\n",
      "Epoch 12/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.9834 - loss: 0.0543 - val_accuracy: 0.9898 - val_loss: 0.0364\n",
      "Epoch 13/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.9824 - loss: 0.0557 - val_accuracy: 0.9904 - val_loss: 0.0332\n",
      "Epoch 14/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 49ms/step - accuracy: 0.9838 - loss: 0.0531 - val_accuracy: 0.9914 - val_loss: 0.0282\n",
      "Epoch 15/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9834 - loss: 0.0524 - val_accuracy: 0.9905 - val_loss: 0.0333\n",
      "Epoch 16/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9855 - loss: 0.0473 - val_accuracy: 0.9921 - val_loss: 0.0246\n",
      "Epoch 17/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9849 - loss: 0.0497 - val_accuracy: 0.9897 - val_loss: 0.0359\n",
      "Epoch 18/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9861 - loss: 0.0439 - val_accuracy: 0.9902 - val_loss: 0.0385\n",
      "Epoch 19/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.9872 - loss: 0.0424 - val_accuracy: 0.9901 - val_loss: 0.0332\n",
      "Epoch 20/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9863 - loss: 0.0443 - val_accuracy: 0.9905 - val_loss: 0.0342\n",
      "Epoch 21/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9879 - loss: 0.0420 - val_accuracy: 0.9918 - val_loss: 0.0285\n",
      "Epoch 22/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9870 - loss: 0.0422 - val_accuracy: 0.9894 - val_loss: 0.0348\n",
      "Epoch 23/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9875 - loss: 0.0384 - val_accuracy: 0.9899 - val_loss: 0.0355\n",
      "Epoch 24/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9879 - loss: 0.0411 - val_accuracy: 0.9919 - val_loss: 0.0263\n",
      "Epoch 25/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9881 - loss: 0.0372 - val_accuracy: 0.9921 - val_loss: 0.0267\n",
      "Epoch 26/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9892 - loss: 0.0364 - val_accuracy: 0.9924 - val_loss: 0.0254\n",
      "Epoch 27/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.9884 - loss: 0.0382 - val_accuracy: 0.9892 - val_loss: 0.0365\n",
      "Epoch 28/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9888 - loss: 0.0354 - val_accuracy: 0.9862 - val_loss: 0.0490\n",
      "Epoch 29/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9893 - loss: 0.0343 - val_accuracy: 0.9898 - val_loss: 0.0353\n",
      "Epoch 30/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9897 - loss: 0.0317 - val_accuracy: 0.9917 - val_loss: 0.0296\n",
      "Epoch 31/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9897 - loss: 0.0334 - val_accuracy: 0.9921 - val_loss: 0.0265\n",
      "Epoch 32/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.9891 - loss: 0.0371 - val_accuracy: 0.9891 - val_loss: 0.0357\n",
      "Epoch 33/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.9895 - loss: 0.0340 - val_accuracy: 0.9910 - val_loss: 0.0308\n",
      "Epoch 34/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.9899 - loss: 0.0336 - val_accuracy: 0.9922 - val_loss: 0.0243\n",
      "Epoch 35/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.9891 - loss: 0.0339 - val_accuracy: 0.9908 - val_loss: 0.0280\n",
      "Epoch 36/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9897 - loss: 0.0307 - val_accuracy: 0.9910 - val_loss: 0.0268\n",
      "Epoch 37/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9892 - loss: 0.0345 - val_accuracy: 0.9911 - val_loss: 0.0265\n",
      "Epoch 38/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9903 - loss: 0.0304 - val_accuracy: 0.9886 - val_loss: 0.0383\n",
      "Epoch 39/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 42ms/step - accuracy: 0.9902 - loss: 0.0320 - val_accuracy: 0.9913 - val_loss: 0.0275\n",
      "Epoch 40/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9902 - loss: 0.0302 - val_accuracy: 0.9888 - val_loss: 0.0364\n",
      "Epoch 41/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9906 - loss: 0.0313 - val_accuracy: 0.9910 - val_loss: 0.0313\n",
      "Epoch 42/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9905 - loss: 0.0317 - val_accuracy: 0.9922 - val_loss: 0.0269\n",
      "Epoch 43/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 45ms/step - accuracy: 0.9915 - loss: 0.0270 - val_accuracy: 0.9907 - val_loss: 0.0299\n",
      "Epoch 44/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 44ms/step - accuracy: 0.9915 - loss: 0.0282 - val_accuracy: 0.9906 - val_loss: 0.0283\n",
      "Epoch 45/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9909 - loss: 0.0294 - val_accuracy: 0.9909 - val_loss: 0.0303\n",
      "Epoch 46/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9911 - loss: 0.0290 - val_accuracy: 0.9910 - val_loss: 0.0314\n",
      "Epoch 47/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9913 - loss: 0.0285 - val_accuracy: 0.9910 - val_loss: 0.0300\n",
      "Epoch 48/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9906 - loss: 0.0285 - val_accuracy: 0.9906 - val_loss: 0.0324\n",
      "Epoch 49/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9911 - loss: 0.0278 - val_accuracy: 0.9925 - val_loss: 0.0282\n",
      "Epoch 50/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.9918 - loss: 0.0263 - val_accuracy: 0.9895 - val_loss: 0.0370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x217bec9caf0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,       # Randomly rotate images in the range (degrees, 0 to 20)\n",
    "    width_shift_range=0.1,   # Randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # Randomly shift images vertically (fraction of total height)\n",
    "    zoom_range=0.1,           # Randomly zoom images by up to 10%\n",
    "    horizontal_flip=False,   # Not flipping since MNIST digits should not be flipped\n",
    ")\n",
    "\n",
    "md2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "md2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "md2.fit(datagen.flow(x_train, y_train, batch_size=128), epochs=50, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9894999861717224\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = md2.evaluate(x_test, y_test, verbose = 0)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2(c) (2 points)\n",
    "\n",
    "What model would you use to predict the digit label in the `mnist` data set? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results I would choose model 2 because it has the highest accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
