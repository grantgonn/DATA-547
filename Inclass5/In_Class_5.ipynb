{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 \n",
    "\n",
    "In this exercise, we will use a deep neural network to predict the digit labels on the popular `mnist` data set. For more information, see this [link](https://en.wikipedia.org/wiki/MNIST_database)\n",
    "\n",
    "### Exercise 1(a) (2 points)\n",
    "\n",
    "Load the below libraries.\n",
    "\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(b) (3 points)\n",
    "\n",
    "Load the `mnist` data as `train` and `test` data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(c) (5 points)\n",
    "\n",
    "Visualize the first 5 digit images from the `train` data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_images = 5\n",
    "\n",
    "fig, axes = plt.subplots(1, num_images, figsize=(20,20))\n",
    "for i in range(num_images):\n",
    "    axes[i].imshow(x_train[i], cmap='gray')\n",
    "    axes[i].set_title(y_train[i])\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_images = 5\n",
    "\n",
    "fig, axes = plt.subplots(1, num_images, figsize=(20,20))\n",
    "for i in range(num_images):\n",
    "    sample = np.random.randint(0, x_train.shape[0])\n",
    "    axes[i].imshow(x_train[sample], cmap='gray')\n",
    "    axes[i].set_title(y_train[sample])\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1(d) (10 points)\n",
    "\n",
    "Build a deep neural network as follows:\n",
    "\n",
    "- Reshape the input features. Use 784.\n",
    "- Standardize the input features. Divide the input values by 255.\n",
    "- Change the digit labels to 0-1 encoding.\n",
    "- Build a deep neural network with 2 layers with 128 neurons. Use `relu` as the activation function in the hidden layers and `softmax` as the activation function in the output.\n",
    "- Compile the network with the following:\n",
    "    - `optimizer='adam'`\n",
    "    - `loss='categorical_crossentropy'`\n",
    "    - `metrics=['accuracy']`\n",
    "- Train the deep neural network with `epochs=50`, `batch_size=128`, and `validation_split=0.2`.\n",
    "- Evaluate the model in the `test` data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8143 - loss: 0.6575 - val_accuracy: 0.9523 - val_loss: 0.1622\n",
      "Epoch 2/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1460 - val_accuracy: 0.9629 - val_loss: 0.1216\n",
      "Epoch 3/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9706 - loss: 0.0975 - val_accuracy: 0.9647 - val_loss: 0.1119\n",
      "Epoch 4/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0702 - val_accuracy: 0.9696 - val_loss: 0.0992\n",
      "Epoch 5/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.0548 - val_accuracy: 0.9721 - val_loss: 0.0959\n",
      "Epoch 6/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9882 - loss: 0.0412 - val_accuracy: 0.9714 - val_loss: 0.0930\n",
      "Epoch 7/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9908 - loss: 0.0314 - val_accuracy: 0.9735 - val_loss: 0.0964\n",
      "Epoch 8/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0253 - val_accuracy: 0.9752 - val_loss: 0.0928\n",
      "Epoch 9/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0212 - val_accuracy: 0.9751 - val_loss: 0.0891\n",
      "Epoch 10/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0174 - val_accuracy: 0.9758 - val_loss: 0.0949\n",
      "Epoch 11/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0168 - val_accuracy: 0.9758 - val_loss: 0.0962\n",
      "Epoch 12/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0134 - val_accuracy: 0.9747 - val_loss: 0.1055\n",
      "Epoch 13/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0109 - val_accuracy: 0.9743 - val_loss: 0.1089\n",
      "Epoch 14/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0081 - val_accuracy: 0.9756 - val_loss: 0.1064\n",
      "Epoch 15/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0075 - val_accuracy: 0.9741 - val_loss: 0.1237\n",
      "Epoch 16/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0077 - val_accuracy: 0.9743 - val_loss: 0.1133\n",
      "Epoch 17/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0092 - val_accuracy: 0.9731 - val_loss: 0.1214\n",
      "Epoch 18/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.9780 - val_loss: 0.1138\n",
      "Epoch 19/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0071 - val_accuracy: 0.9759 - val_loss: 0.1166\n",
      "Epoch 20/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0055 - val_accuracy: 0.9789 - val_loss: 0.1075\n",
      "Epoch 21/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0055 - val_accuracy: 0.9762 - val_loss: 0.1180\n",
      "Epoch 22/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0133 - val_accuracy: 0.9761 - val_loss: 0.1242\n",
      "Epoch 23/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0077 - val_accuracy: 0.9775 - val_loss: 0.1171\n",
      "Epoch 24/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9790 - val_loss: 0.1125\n",
      "Epoch 25/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.7383e-04 - val_accuracy: 0.9775 - val_loss: 0.1297\n",
      "Epoch 26/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0037 - val_accuracy: 0.9744 - val_loss: 0.1429\n",
      "Epoch 27/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0117 - val_accuracy: 0.9762 - val_loss: 0.1302\n",
      "Epoch 28/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0119 - val_accuracy: 0.9762 - val_loss: 0.1258\n",
      "Epoch 29/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.9731 - val_loss: 0.1535\n",
      "Epoch 30/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0075 - val_accuracy: 0.9774 - val_loss: 0.1281\n",
      "Epoch 31/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 6.5834e-04 - val_accuracy: 0.9803 - val_loss: 0.1170\n",
      "Epoch 32/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 3.0949e-04 - val_accuracy: 0.9809 - val_loss: 0.1189\n",
      "Epoch 33/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1860e-04 - val_accuracy: 0.9804 - val_loss: 0.1239\n",
      "Epoch 34/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9707 - val_loss: 0.1750\n",
      "Epoch 35/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9948 - loss: 0.0175 - val_accuracy: 0.9779 - val_loss: 0.1341\n",
      "Epoch 36/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0038 - val_accuracy: 0.9771 - val_loss: 0.1365\n",
      "Epoch 37/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.9787 - val_loss: 0.1315\n",
      "Epoch 38/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 7.5360e-04 - val_accuracy: 0.9797 - val_loss: 0.1248\n",
      "Epoch 39/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.3714e-04 - val_accuracy: 0.9787 - val_loss: 0.1335\n",
      "Epoch 40/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9718 - val_loss: 0.1625\n",
      "Epoch 41/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0171 - val_accuracy: 0.9779 - val_loss: 0.1507\n",
      "Epoch 42/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0070 - val_accuracy: 0.9781 - val_loss: 0.1327\n",
      "Epoch 43/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.9786 - val_loss: 0.1386\n",
      "Epoch 44/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9820 - val_loss: 0.1303\n",
      "Epoch 45/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 8.8332e-04 - val_accuracy: 0.9793 - val_loss: 0.1297\n",
      "Epoch 46/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0072 - val_accuracy: 0.9770 - val_loss: 0.1468\n",
      "Epoch 47/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 0.9778 - val_loss: 0.1376\n",
      "Epoch 48/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0050 - val_accuracy: 0.9782 - val_loss: 0.1502\n",
      "Epoch 49/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9737 - val_loss: 0.1818\n",
      "Epoch 50/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0096 - val_accuracy: 0.9786 - val_loss: 0.1444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22592e4e050>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "md1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "md1.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "md1.fit(x_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9760 - loss: 0.1644\n",
      "0.9797999858856201\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = md1.evaluate(x_test, y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 \n",
    "\n",
    "In this exercise, we will build a Convolutional Neural Network (CNN) to predict digit labels on the popular `mnist` data set.\n",
    "\n",
    "### Exercise 2(a) (3 points)\n",
    "\n",
    "Load the `mnist` data as `train` and `test` data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2(b) (12 points)\n",
    "\n",
    "Build a CNN model as follows:\n",
    "\n",
    "- Change the digit labels to 0-1 encoding.\n",
    "- The CNN model should have the following layers in the given order:\n",
    "    - `Conv2D` with 32 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Conv2D` with 64 filters, `kernel_size=(3,3)` and `activation=relu`\n",
    "    - `MaxPooling2D` with `pool_size=(2,2)`\n",
    "    - `Flatten`\n",
    "    - `Dense` with 128 neurons and `activation=relu`\n",
    "    - `Dense` with 10 neurons and `activation=softmax`\n",
    "- Compile the network with the following:\n",
    "    - `optimizer='adam'`\n",
    "    - `loss='categorical_crossentropy'`\n",
    "    - `metrics=['accuracy']`\n",
    "- Train the deep neural network with `epochs=50`, `batch_size=128`, and `validation_split=0.1`.\n",
    "- Evaluate the model on the `test` data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.7843 - loss: 4.4729 - val_accuracy: 0.9725 - val_loss: 0.0942\n",
      "Epoch 2/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9751 - loss: 0.0774 - val_accuracy: 0.9790 - val_loss: 0.0730\n",
      "Epoch 3/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9871 - loss: 0.0422 - val_accuracy: 0.9766 - val_loss: 0.0863\n",
      "Epoch 4/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9901 - loss: 0.0301 - val_accuracy: 0.9830 - val_loss: 0.0613\n",
      "Epoch 5/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9921 - loss: 0.0226 - val_accuracy: 0.9810 - val_loss: 0.0751\n",
      "Epoch 6/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9925 - loss: 0.0212 - val_accuracy: 0.9833 - val_loss: 0.0689\n",
      "Epoch 7/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9941 - loss: 0.0162 - val_accuracy: 0.9828 - val_loss: 0.0844\n",
      "Epoch 8/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9928 - loss: 0.0187 - val_accuracy: 0.9821 - val_loss: 0.0810\n",
      "Epoch 9/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9938 - loss: 0.0180 - val_accuracy: 0.9847 - val_loss: 0.0697\n",
      "Epoch 10/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9946 - loss: 0.0150 - val_accuracy: 0.9864 - val_loss: 0.0638\n",
      "Epoch 11/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9951 - loss: 0.0161 - val_accuracy: 0.9858 - val_loss: 0.0718\n",
      "Epoch 12/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9955 - loss: 0.0139 - val_accuracy: 0.9864 - val_loss: 0.0671\n",
      "Epoch 13/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9967 - loss: 0.0108 - val_accuracy: 0.9844 - val_loss: 0.0799\n",
      "Epoch 14/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9967 - loss: 0.0099 - val_accuracy: 0.9853 - val_loss: 0.0844\n",
      "Epoch 15/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9957 - loss: 0.0126 - val_accuracy: 0.9880 - val_loss: 0.0704\n",
      "Epoch 16/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9969 - loss: 0.0094 - val_accuracy: 0.9843 - val_loss: 0.0896\n",
      "Epoch 17/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9959 - loss: 0.0145 - val_accuracy: 0.9852 - val_loss: 0.0871\n",
      "Epoch 18/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9962 - loss: 0.0113 - val_accuracy: 0.9878 - val_loss: 0.0694\n",
      "Epoch 19/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9982 - loss: 0.0055 - val_accuracy: 0.9847 - val_loss: 0.0921\n",
      "Epoch 20/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9963 - loss: 0.0116 - val_accuracy: 0.9869 - val_loss: 0.0874\n",
      "Epoch 21/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9959 - loss: 0.0137 - val_accuracy: 0.9864 - val_loss: 0.0735\n",
      "Epoch 22/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9966 - loss: 0.0103 - val_accuracy: 0.9876 - val_loss: 0.0735\n",
      "Epoch 23/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9981 - loss: 0.0062 - val_accuracy: 0.9808 - val_loss: 0.1260\n",
      "Epoch 24/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9970 - loss: 0.0094 - val_accuracy: 0.9839 - val_loss: 0.0880\n",
      "Epoch 25/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9976 - loss: 0.0072 - val_accuracy: 0.9847 - val_loss: 0.0987\n",
      "Epoch 26/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9971 - loss: 0.0105 - val_accuracy: 0.9852 - val_loss: 0.0933\n",
      "Epoch 27/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9968 - loss: 0.0121 - val_accuracy: 0.9862 - val_loss: 0.0930\n",
      "Epoch 28/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9980 - loss: 0.0070 - val_accuracy: 0.9872 - val_loss: 0.0960\n",
      "Epoch 29/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9973 - loss: 0.0091 - val_accuracy: 0.9868 - val_loss: 0.0941\n",
      "Epoch 30/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9975 - loss: 0.0085 - val_accuracy: 0.9889 - val_loss: 0.0896\n",
      "Epoch 31/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9983 - loss: 0.0048 - val_accuracy: 0.9865 - val_loss: 0.1051\n",
      "Epoch 32/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9981 - loss: 0.0069 - val_accuracy: 0.9866 - val_loss: 0.1152\n",
      "Epoch 33/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9983 - loss: 0.0071 - val_accuracy: 0.9873 - val_loss: 0.0945\n",
      "Epoch 34/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9982 - loss: 0.0070 - val_accuracy: 0.9880 - val_loss: 0.1008\n",
      "Epoch 35/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9975 - loss: 0.0078 - val_accuracy: 0.9851 - val_loss: 0.1115\n",
      "Epoch 36/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9977 - loss: 0.0095 - val_accuracy: 0.9881 - val_loss: 0.0977\n",
      "Epoch 37/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.9872 - val_loss: 0.1127\n",
      "Epoch 38/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9981 - loss: 0.0088 - val_accuracy: 0.9883 - val_loss: 0.0952\n",
      "Epoch 39/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9994 - loss: 0.0019 - val_accuracy: 0.9886 - val_loss: 0.1135\n",
      "Epoch 40/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9846 - val_loss: 0.1579\n",
      "Epoch 41/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9974 - loss: 0.0125 - val_accuracy: 0.9882 - val_loss: 0.1246\n",
      "Epoch 42/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9971 - loss: 0.0143 - val_accuracy: 0.9884 - val_loss: 0.1123\n",
      "Epoch 43/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9984 - loss: 0.0063 - val_accuracy: 0.9892 - val_loss: 0.1135\n",
      "Epoch 44/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9991 - loss: 0.0047 - val_accuracy: 0.9874 - val_loss: 0.1015\n",
      "Epoch 45/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9881 - val_loss: 0.1312\n",
      "Epoch 46/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 0.9883 - val_loss: 0.1130\n",
      "Epoch 47/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9985 - loss: 0.0057 - val_accuracy: 0.9864 - val_loss: 0.1387\n",
      "Epoch 48/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9982 - loss: 0.0092 - val_accuracy: 0.9883 - val_loss: 0.1002\n",
      "Epoch 49/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9983 - loss: 0.0065 - val_accuracy: 0.9876 - val_loss: 0.1374\n",
      "Epoch 50/50\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.9888 - val_loss: 0.1084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22592d45ed0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "md2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "md2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "md2.fit(x_train, y_train, epochs = 50, batch_size = 128, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9878000020980835\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = md2.evaluate(x_test, y_test, verbose = 0)\n",
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
